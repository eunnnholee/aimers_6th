{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242097ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting rtdl_num_embeddings\n",
      "  Downloading rtdl_num_embeddings-0.0.11-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: torch<3,>=1.12 in /home/elicer/.local/lib/python3.10/site-packages (from rtdl_num_embeddings) (2.5.1+cu124)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (10.3.5.147)\n",
      "Requirement already satisfied: fsspec in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (2024.6.1)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (3.1.0)\n",
      "Requirement already satisfied: networkx in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (3.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.5.8)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (4.13.1)\n",
      "Requirement already satisfied: jinja2 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
      "Requirement already satisfied: filelock in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/elicer/.local/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/elicer/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch<3,>=1.12->rtdl_num_embeddings) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/elicer/.local/lib/python3.10/site-packages (from jinja2->torch<3,>=1.12->rtdl_num_embeddings) (2.1.5)\n",
      "Installing collected packages: rtdl_num_embeddings\n",
      "Successfully installed rtdl_num_embeddings-0.0.11\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -q install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n",
    "!pip -q install pandas numpy ipynbname scikit-learn\n",
    "!pip install rtdl_num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0919eeb-bbb3-48d4-ae3f-3dac6b370d95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:18:17.297674Z",
     "start_time": "2025-04-04T12:18:14.983465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from tabm_reference import Model, make_parameter_groups\n",
    "import rtdl_num_embeddings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8b152b-c7a9-40f1-975a-516b764fcadd",
   "metadata": {},
   "source": [
    "## 2. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feed2e5f-fb44-4ec5-8546-711ee29221cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:18:18.366112Z",
     "start_time": "2025-04-04T12:18:17.303856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256351, 68) (90067, 67)\n"
     ]
    }
   ],
   "source": [
    "train_path = f'../data/train.csv'\n",
    "test_path = f'../data/test.csv'\n",
    "sample_path = f'../data/sample_submission.csv'\n",
    "\n",
    "# 학습/평가 데이터 로드\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63299de32ba2bec9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:18:24.197964Z",
     "start_time": "2025-04-04T12:18:18.510236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수치형 변수: 57개 \n",
      "['임신 시도 또는 마지막 임신 경과 연수', '배란 자극 여부', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인', '불명확 불임 원인', '불임 원인 - 난관 질환', '불임 원인 - 남성 요인', '불임 원인 - 배란 장애', '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증', '불임 원인 - 정자 농도', '불임 원인 - 정자 운동성', '불임 원인 - 정자 형태', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', 'IVF 임신 횟수', 'DI 임신 횟수', '총 출산 횟수', 'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '이식된 배아 수', '미세주입 배아 이식 수', '저장된 배아 수', '미세주입 후 저장된 배아 수', '해동된 배아 수', '해동 난자 수', '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수', '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '대리모 여부', 'PGD 시술 여부', 'PGS 시술 여부', '난자 혼합 경과일', '배아 이식 경과일', '배아 해동 경과일', '시술_임신', '배아생성이유_기증용', '배아생성이유_난자 저장용', '배아생성이유_배아 저장용', '배아생성이유_현재 시술용']\n",
      "범주형 변수: 8개 \n",
      "['시술 시기 코드', '시술 당시 나이', '배란 유도 유형', '난자 출처', '정자 출처', '난자 기증자 나이', '정자 기증자 나이', '시술유형_통합']\n",
      "(256351, 66) (90067, 65)\n"
     ]
    }
   ],
   "source": [
    "from preprocess_DL import all_process\n",
    "\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "train, test = all_process(train, test)\n",
    "\n",
    "cat_cols = [col for col in train.columns if pd.api.types.is_categorical_dtype(train[col])]\n",
    "numeric_cols = [col for col in train.columns if col not in cat_cols and col != '임신 성공 여부']\n",
    "\n",
    "print(f'수치형 변수: {len(numeric_cols)}개 \\n{numeric_cols}')\n",
    "print(f'범주형 변수: {len(cat_cols)}개 \\n{cat_cols}')\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7175bdaadb738a88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:18:24.229963Z",
     "start_time": "2025-04-04T12:18:24.214964Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_to_tensor(train, val, test=None):\n",
    "    if test is None:\n",
    "        data_numpy = {\n",
    "            'train': {'x_cat': train[cat_cols].values, 'x_cont': train[numeric_cols].values, 'y': train['임신 성공 여부'].values},\n",
    "            'val': {'x_cat': val[cat_cols].values, 'x_cont': val[numeric_cols].values, 'y': val['임신 성공 여부'].values},\n",
    "        }\n",
    "        data = {\n",
    "            part: {k: torch.as_tensor(v, device=device) for k, v in data_numpy[part].items()}\n",
    "            for part in data_numpy\n",
    "        }\n",
    "        data['train']['y'] = data['train']['y'].long()\n",
    "        data['val']['y'] = data['val']['y'].long()\n",
    "        return data\n",
    "    else:\n",
    "        data_numpy = {\n",
    "            'train': {'x_cat': train[cat_cols].values, 'x_cont': train[numeric_cols].values, 'y': train['임신 성공 여부'].values},\n",
    "            'val': {'x_cat': val[cat_cols].values, 'x_cont': val[numeric_cols].values, 'y': val['임신 성공 여부'].values},\n",
    "            'test': {'x_cat': test[cat_cols].values, 'x_cont': test[numeric_cols].values},\n",
    "        }\n",
    "        data = {\n",
    "            part: {k: torch.as_tensor(v, device=device) for k, v in data_numpy[part].items()}\n",
    "            for part in data_numpy\n",
    "        }\n",
    "        data['train']['y'] = data['train']['y'].long()\n",
    "        data['val']['y'] = data['val']['y'].long()\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff599c4b9c777fd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:18:24.529322Z",
     "start_time": "2025-04-04T12:18:24.247037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "[7, 7, 2, 3, 4, 5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "def get_feature_info(train):\n",
    "    n_num_features_ = len(numeric_cols)\n",
    "    cat_cardinalities_ = [train[col].nunique() for col in cat_cols]\n",
    "\n",
    "    return n_num_features_, cat_cardinalities_\n",
    "\n",
    "n_num_features, cat_cardinalities = get_feature_info(train)\n",
    "bins = rtdl_num_embeddings.compute_bins(torch.tensor(train[numeric_cols].values))\n",
    "\n",
    "model_config = {\n",
    "    'n_num_features': n_num_features,\n",
    "    'cat_cardinalities': cat_cardinalities,\n",
    "    'n_classes': 2,\n",
    "    'backbone': {\n",
    "        'type': 'MLP',\n",
    "        'n_blocks': 3 if bins is None else 2,\n",
    "        'd_block': 512,\n",
    "        'dropout': 0.1,\n",
    "    },\n",
    "    'bins': bins,\n",
    "    'num_embeddings': (\n",
    "        None if bins is None else {\n",
    "            'type': 'PiecewiseLinearEmbeddings',\n",
    "            'd_embedding': 16,\n",
    "            'activation': False,\n",
    "            'version': 'B',\n",
    "        }\n",
    "    ),\n",
    "    'arch_type': 'tabm-mini',\n",
    "    'k': 32,\n",
    "    'share_training_batches': True,\n",
    "}\n",
    "\n",
    "model = Model(**model_config).to(device)\n",
    "\n",
    "print(n_num_features)\n",
    "print(cat_cardinalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32f926927cf34e34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:18:25.462175Z",
     "start_time": "2025-04-04T12:18:24.562323Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(make_parameter_groups(model), lr=2e-3, weight_decay=3e-4)\n",
    "\n",
    "# 기본 손실 함수 설정 (여기서는 분류 문제이므로 cross_entropy)\n",
    "base_loss_fn = F.cross_entropy\n",
    "\n",
    "def loss_fn(y_pred, y_true):\n",
    "    # 모델 출력 y_pred.shape: (batch_size, k, n_classes)\n",
    "    k = y_pred.shape[-2]  # k 예측 개수\n",
    "    # 모든 예측에 대해 손실을 계산\n",
    "    return base_loss_fn(\n",
    "        y_pred.flatten(0, 1),\n",
    "        y_true.repeat_interleave(k) if model.share_training_batches else y_true\n",
    "    )\n",
    "\n",
    "def apply_model(part: str, idx: Tensor) -> Tensor:\n",
    "    return (\n",
    "        model(\n",
    "            data[part]['x_cont'][idx],\n",
    "            data[part]['x_cat'][idx] if 'x_cat' in data[part] else None,\n",
    "        )\n",
    "        .squeeze(-1)  # Remove the last dimension for regression tasks.\n",
    "        .float()\n",
    "    )\n",
    "\n",
    "def evaluate(part: str, metric: str = 'auc') -> float:\n",
    "    model.eval()\n",
    "    eval_batch_size = 2048\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for idx in torch.arange(len(data[part]['y']), device=device).split(eval_batch_size):\n",
    "            preds = apply_model(part, idx)\n",
    "            all_preds.append(preds)\n",
    "            all_targets.append(data[part]['y'][idx])\n",
    "    # 예측 결과: (N, k, n_classes) -> (N, n_classes) (k개의 예측의 평균)\n",
    "    y_pred = torch.cat(all_preds).cpu().numpy()\n",
    "    y_true = torch.cat(all_targets).cpu().numpy()\n",
    "\n",
    "    # 소프트맥스를 통해 확률로 변환한 뒤 k개 예측에 대해 평균을 냅니다.\n",
    "    y_pred = scipy.special.softmax(y_pred, axis=-1)\n",
    "    y_pred = y_pred.mean(1)  # shape: (N, n_classes)\n",
    "\n",
    "    if metric == 'auc':\n",
    "        auc = roc_auc_score(y_true, y_pred[:, 1])\n",
    "        return float(auc)\n",
    "    elif metric == 'loss':\n",
    "        total_loss = 0.0\n",
    "        total_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for idx in torch.arange(len(data[part]['y']), device=device).split(eval_batch_size):\n",
    "                preds = apply_model(part, idx)\n",
    "                batch_loss = loss_fn(preds, data[part]['y'][idx])\n",
    "                total_loss += batch_loss.item() * idx.size(0)\n",
    "                total_samples += idx.size(0)\n",
    "        return total_loss / total_samples\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown metric: {metric}\")\n",
    "\n",
    "\n",
    "def predict_proba(part: str) -> np.ndarray:\n",
    "    model.eval()\n",
    "    eval_batch_size = 2048\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        num_samples = len(data[part]['x_cont'])\n",
    "        for idx in torch.arange(num_samples, device=device).split(eval_batch_size):\n",
    "            batch_pred = apply_model(part, idx)\n",
    "            preds.append(batch_pred)\n",
    "\n",
    "    # 모든 배치의 예측값을 하나의 텐서로 합칩니다.\n",
    "    y_pred = torch.cat(preds).cpu().numpy()\n",
    "    y_pred = scipy.special.softmax(y_pred, axis=-1)\n",
    "\n",
    "    return y_pred.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e29f831df3bcd7eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:18:25.508176Z",
     "start_time": "2025-04-04T12:18:25.494176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# 1. 자동 혼합 정밀도(AMP)에서 사용할 데이터 타입(amp_dtype)을 설정합니다.\n",
    "if torch.cuda.is_available():\n",
    "    # CUDA를 사용할 수 있으면, bfloat16 지원 여부를 확인합니다.\n",
    "    if torch.cuda.is_bf16_supported():\n",
    "        amp_dtype = torch.bfloat16  # bfloat16을 지원하면 bfloat16을 사용합니다.\n",
    "    else:\n",
    "        amp_dtype = torch.float16   # bfloat16을 지원하지 않으면 float16을 사용합니다.\n",
    "else:\n",
    "    amp_dtype = None  # CUDA를 사용할 수 없으면 AMP를 사용하지 않습니다.\n",
    "\n",
    "# 2. AMP 기능을 활성화할지 결정합니다.\n",
    "amp_enabled = False and (amp_dtype is not None)\n",
    "\n",
    "# 3. GradScaler는 float16 모드에서 수치 안정성을 위해 사용됩니다.\n",
    "# amp_dtype이 torch.float16일 때만 GradScaler를 생성합니다.\n",
    "if amp_dtype == torch.float16:\n",
    "    grad_scaler = torch.cuda.amp.GradScaler()\n",
    "else:\n",
    "    grad_scaler = None\n",
    "\n",
    "print(grad_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e18ee9209a5acd26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:23:07.461607Z",
     "start_time": "2025-04-04T12:18:25.540188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.5108, Val Loss: 0.4917, Val AUC: 0.7382058350042879\n",
      "[Epoch 2] Train Loss: 0.4923, Val Loss: 0.4903, Val AUC: 0.7395313077779773\n",
      "[Epoch 3] Train Loss: 0.4903, Val Loss: 0.4892, Val AUC: 0.7398862351161449\n",
      "[Epoch 4] Train Loss: 0.4897, Val Loss: 0.4897, Val AUC: 0.739568138764529\n",
      "[Epoch 5] Train Loss: 0.4895, Val Loss: 0.4902, Val AUC: 0.7405248053249772\n",
      "[Epoch 6] Train Loss: 0.4887, Val Loss: 0.4891, Val AUC: 0.741125917163734\n",
      "[Epoch 7] Train Loss: 0.4886, Val Loss: 0.4888, Val AUC: 0.7406652707383262\n",
      "[Epoch 8] Train Loss: 0.4879, Val Loss: 0.4887, Val AUC: 0.7414011777140268\n",
      "[Epoch 9] Train Loss: 0.4873, Val Loss: 0.4887, Val AUC: 0.740949652174405\n",
      "[Epoch 10] Train Loss: 0.4872, Val Loss: 0.4890, Val AUC: 0.740932810103416\n",
      "[Epoch 11] Train Loss: 0.4869, Val Loss: 0.4890, Val AUC: 0.7415044885221078\n",
      "[Epoch 12] Train Loss: 0.4863, Val Loss: 0.4888, Val AUC: 0.7415987777139474\n",
      "\n",
      "Result:\n",
      "{'epoch': 7, 'train_loss': 0.48790616405993753, 'val_loss': 0.4886660148307333}\n",
      "[Epoch 1] Train Loss: 0.5092, Val Loss: 0.4944, Val AUC: 0.7352537742028116\n",
      "[Epoch 2] Train Loss: 0.4925, Val Loss: 0.4895, Val AUC: 0.7384456928532197\n",
      "[Epoch 3] Train Loss: 0.4909, Val Loss: 0.4906, Val AUC: 0.7396124452704295\n",
      "[Epoch 4] Train Loss: 0.4902, Val Loss: 0.4906, Val AUC: 0.7405782331615592\n",
      "[Epoch 5] Train Loss: 0.4895, Val Loss: 0.4892, Val AUC: 0.7405373548476606\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     85\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(apply_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_idx), data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m][batch_idx])\n\u001b[0;32m---> 86\u001b[0m train_loss_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m batch_idx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grad_scaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = 333\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "test_preds = []\n",
    "val_scores = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train['임신 성공 여부'])):\n",
    "    fold_train = train.iloc[train_idx].copy().reset_index(drop=True)\n",
    "    fold_valid = train.iloc[valid_idx].copy().reset_index(drop=True)\n",
    "    fold_train2 = fold_train.copy()\n",
    "    fold_test = test.copy()\n",
    "\n",
    "    fold_train, fold_valid = all_process(fold_train, fold_valid)\n",
    "    _, fold_test = all_process(fold_train2, fold_test)\n",
    "\n",
    "    cat_cols = [col for col in fold_train.columns if pd.api.types.is_categorical_dtype(fold_train[col])]\n",
    "    numeric_cols = [col for col in fold_train.columns if col not in cat_cols and col != '임신 성공 여부']\n",
    "\n",
    "    bins = rtdl_num_embeddings.compute_bins(torch.tensor(fold_train[numeric_cols].values))\n",
    "    n_num_features, cat_cardinalities = get_feature_info(fold_train)\n",
    "\n",
    "    model_config = {\n",
    "        'n_num_features': n_num_features,\n",
    "        'cat_cardinalities': cat_cardinalities,\n",
    "        'n_classes': 2,\n",
    "        'backbone': {\n",
    "            'type': 'MLP',\n",
    "            'n_blocks': 3 if bins is None else 2,\n",
    "            'd_block': 512,\n",
    "            'dropout': 0.1,\n",
    "        },\n",
    "        'bins': bins,\n",
    "        'num_embeddings': (\n",
    "            None if bins is None else {\n",
    "                'type': 'PiecewiseLinearEmbeddings',\n",
    "                'd_embedding': 16,\n",
    "                'activation': False,\n",
    "                'version': 'B',\n",
    "            }\n",
    "        ),\n",
    "        'arch_type': 'tabm-mini',\n",
    "        'k': 32,\n",
    "        'share_training_batches': True,\n",
    "    }\n",
    "    model = Model(**model_config).to(device)\n",
    "    optimizer = torch.optim.AdamW(make_parameter_groups(model), lr=2e-3, weight_decay=3e-4)\n",
    "\n",
    "    data = df_to_tensor(fold_train, fold_valid, fold_test)\n",
    "\n",
    "    train_size = len(fold_train)\n",
    "    batch_size = 1024\n",
    "    epoch_size = math.ceil(train_size / batch_size)\n",
    "\n",
    "    best = {'epoch': -1, 'train_loss': float('inf'), 'val_loss': float('inf')}\n",
    "\n",
    "    patience = 3\n",
    "    remaining_patience = patience\n",
    "\n",
    "    save_path = 'best_model_tabm.pt'\n",
    "    n_epochs = 1000000\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss_epoch = 0.0  # 전체 학습 손실 누적\n",
    "        batches = (\n",
    "            torch.randperm(train_size, device=device).split(batch_size)\n",
    "            if model.share_training_batches\n",
    "            else [\n",
    "                x.transpose(0, 1).flatten()\n",
    "                for x in torch.rand((model.k, train_size), device=device)\n",
    "                .argsort(dim=1)\n",
    "                .split(batch_size, dim=1)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # for batch_idx in tqdm(batches, desc=f'Epoch {epoch}'):\n",
    "        for batch_idx in batches:\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(apply_model('train', batch_idx), data['train']['y'][batch_idx])\n",
    "            train_loss_epoch += loss.item() * batch_idx.size(0)\n",
    "            if grad_scaler is None:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                grad_scaler.scale(loss).backward()  # type: ignore\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "        train_loss_epoch /= train_size\n",
    "\n",
    "        val_loss = evaluate('val', metric='loss')\n",
    "        val_auc = evaluate('val', metric='auc')\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Train Loss: {train_loss_epoch:.4f}, Val Loss: {val_loss:.4f}, Val AUC: {val_auc}\")\n",
    "\n",
    "        if val_loss < best['val_loss']:\n",
    "            best = {'epoch': epoch, 'train_loss': train_loss_epoch, 'val_loss': val_loss}\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            remaining_patience = patience\n",
    "        else:\n",
    "            remaining_patience -= 1\n",
    "\n",
    "        if remaining_patience < 0:\n",
    "            break\n",
    "\n",
    "    print('\\nResult:')\n",
    "    print(best)\n",
    "\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    # print(f\"Best model weights loaded from {save_path}\")\n",
    "\n",
    "    val_score = evaluate('val', metric='auc')\n",
    "    val_scores.append(val_score)\n",
    "\n",
    "    y_test_pred = predict_proba('test')[:, 1]\n",
    "    test_preds.append(y_test_pred)\n",
    "\n",
    "valid_auc = np.mean(val_scores, axis=0)\n",
    "print(f'[Seed {seed}] AVG Valid AUC: {valid_auc:.7f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "577c02463892292d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:23:07.651096Z",
     "start_time": "2025-04-04T12:23:07.620096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>0.002488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>0.155492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>0.106559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>0.536864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90062</th>\n",
       "      <td>TEST_90062</td>\n",
       "      <td>0.001145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90063</th>\n",
       "      <td>TEST_90063</td>\n",
       "      <td>0.298352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90064</th>\n",
       "      <td>TEST_90064</td>\n",
       "      <td>0.460824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90065</th>\n",
       "      <td>TEST_90065</td>\n",
       "      <td>0.219404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90066</th>\n",
       "      <td>TEST_90066</td>\n",
       "      <td>0.000748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90067 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  probability\n",
       "0      TEST_00000     0.000584\n",
       "1      TEST_00001     0.002488\n",
       "2      TEST_00002     0.155492\n",
       "3      TEST_00003     0.106559\n",
       "4      TEST_00004     0.536864\n",
       "...           ...          ...\n",
       "90062  TEST_90062     0.001145\n",
       "90063  TEST_90063     0.298352\n",
       "90064  TEST_90064     0.460824\n",
       "90065  TEST_90065     0.219404\n",
       "90066  TEST_90066     0.000748\n",
       "\n",
       "[90067 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(sample_path)\n",
    "\n",
    "submission['probability'] = np.mean(test_preds, axis=0)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a64672a7154d813d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:23:16.050262Z",
     "start_time": "2025-04-04T12:23:15.971407Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(f'./Submission/TabM_{seed}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189382d5401e8bc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:23:07.826654Z",
     "start_time": "2025-04-04T12:23:07.811647Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
