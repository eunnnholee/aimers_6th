{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WideDeep_TabMlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy==1.26.0\n",
    "# !pip install pandas==2.2.2\n",
    "# !pip install scikit-learn==1.5.1\n",
    "# !pip install scipy==1.14.1\n",
    "# !pip install statsmodels==0.14.2\n",
    "# !pip install joblib==1.4.2\n",
    "# !pip install threadpoolctl==3.5.0\n",
    "# !pip install ipynbname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. 기존의 패키지 정리\n",
    "# !pip uninstall -y torch torchvision torchaudio pytorch-lightning pytorch-tabular\n",
    "\n",
    "# # 2. 호환 가능한 버전으로 재설치\n",
    "# !pip install torch==2.0.1+cu118 --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip install pytorch-tabular==1.1.1 --no-deps\n",
    "# !pip install pytorch-lightning==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-widedeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import shutil\n",
    "import ipynbname\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, log_loss\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "# pytorch-widedeep 라이브러리 import\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "from pytorch_widedeep.models import Wide, TabMlp, WideDeep\n",
    "from pytorch_widedeep.metrics import Accuracy,F1Score\n",
    "from pytorch_widedeep.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "train_path = 'C:/Users/User/Desktop/LG Aimers/LG Aimers 2025/LG Aimers 2025 데이터/train.csv'\n",
    "test_path = 'C:/Users/User/Desktop/LG Aimers/LG Aimers 2025/LG Aimers 2025 데이터/test.csv'\n",
    "sample_path = 'C:/Users/User/Desktop/LG Aimers/LG Aimers 2025/LG Aimers 2025 데이터//sample_submission.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path).drop(columns=[\"ID\"])\n",
    "test = pd.read_csv(test_path).drop(columns=[\"ID\"])\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, FunctionTransformer\n",
    "\n",
    "def drop_columns(df):\n",
    "    cols = [\n",
    "        '불임 원인 - 여성 요인', # 고유값 1\n",
    "        '불임 원인 - 정자 면역학적 요인' # '1'인 데이터가 train, test에서 모두 1개 >> 신뢰할 수 없음\n",
    "    ]\n",
    "    df = df.drop(cols, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def 특정시술유형(train, test):\n",
    "    def categorize_procedure(proc):\n",
    "        tokens = [token.strip() for token in proc.split(\",\") if token.strip() and not token.strip().isdigit()]\n",
    "        # 우선순위에 따른 범주화\n",
    "        if tokens.count(\"Unknown\") >= 1:\n",
    "            return \"Unknown\"\n",
    "        if tokens.count(\"AH\") >= 1:\n",
    "            return \"AH\"\n",
    "        if tokens.count(\"BLASTOCYST\") >= 1:\n",
    "            return \"BLASTOCYST\"\n",
    "        if tokens.count(\"ICSI\") >= 2 or tokens.count(\"IVF\") >= 2:\n",
    "            return \"2ICSI_2IVF\"\n",
    "        if tokens.count(\"IVF\") >= 1 and tokens.count(\"ICSI\") >= 1:\n",
    "            return \"IVF_ICSI\"\n",
    "        if tokens == \"ICSI\":\n",
    "            return \"ICSI\"\n",
    "        if tokens == \"IVF\":\n",
    "            return \"IVF\"\n",
    "        return \",\".join(tokens) if tokens else None\n",
    "\n",
    "    for df in [train, test]:\n",
    "        df['특정 시술 유형'] = df['특정 시술 유형'].str.replace(\" / \", \",\")\n",
    "        df['특정 시술 유형'] = df['특정 시술 유형'].str.replace(\":\", \",\")\n",
    "        df['특정 시술 유형'] = df['특정 시술 유형'].str.replace(\" \", \"\")\n",
    "\n",
    "    counts = train['특정 시술 유형'].value_counts()\n",
    "    allowed_categories = counts[counts >= 100].index.tolist()\n",
    "\n",
    "    # allowed_categories에 속하지 않는 값은 \"Unknown\"으로 대체\n",
    "    train.loc[~train['특정 시술 유형'].isin(allowed_categories), '특정 시술 유형'] = \"Unknown\"\n",
    "    test.loc[~test['특정 시술 유형'].isin(allowed_categories), '특정 시술 유형'] = \"Unknown\"\n",
    "\n",
    "    train['특정 시술 유형'] = train['특정 시술 유형'].apply(categorize_procedure)\n",
    "    test['특정 시술 유형'] = test['특정 시술 유형'].apply(categorize_procedure)\n",
    "\n",
    "    train['시술유형_통합'] = train['시술 유형'].astype(str) + '_' + train['특정 시술 유형'].astype(str)\n",
    "    test['시술유형_통합'] = test['시술 유형'].astype(str) + '_' + test['특정 시술 유형'].astype(str)\n",
    "\n",
    "    drop_cols = ['시술 유형', '특정 시술 유형']\n",
    "    train = train.drop(drop_cols, axis=1)\n",
    "    test = test.drop(drop_cols, axis=1)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def 시술횟수(df_train):\n",
    "    for col in [col for col in df_train.columns if '횟수' in col]:\n",
    "        df_train[col] = df_train[col].replace({'6회 이상':'6회'})\n",
    "        df_train[col] = df_train[col].str[0].astype(int)\n",
    "    df_train['시술_임신'] = df_train['총 임신 횟수'] - df_train['총 시술 횟수']\n",
    "    df_train = df_train.drop('총 시술 횟수', axis=1)\n",
    "    return df_train\n",
    "\n",
    "def numeric_process(train, test, cols_to_numeric=None, value='zero'):\n",
    "    if cols_to_numeric is None:\n",
    "        cols_to_numeric = [\n",
    "            '임신 시도 또는 마지막 임신 경과 연수',\n",
    "            '배란 자극 여부',\n",
    "            '단일 배아 이식 여부',\n",
    "            '착상 전 유전 검사 사용 여부',\n",
    "            '착상 전 유전 진단 사용 여부',\n",
    "            '총 생성 배아 수',\n",
    "            '미세주입된 난자 수',\n",
    "            '미세주입에서 생성된 배아 수',\n",
    "            '이식된 배아 수',\n",
    "            '미세주입 배아 이식 수',\n",
    "            '저장된 배아 수',\n",
    "            '미세주입 후 저장된 배아 수',\n",
    "            '해동된 배아 수',\n",
    "            '해동 난자 수',\n",
    "            '수집된 신선 난자 수',\n",
    "            '저장된 신선 난자 수',\n",
    "            '혼합된 난자 수',\n",
    "            '파트너 정자와 혼합된 난자 수',\n",
    "            '기증자 정자와 혼합된 난자 수',\n",
    "            '동결 배아 사용 여부',\n",
    "            '신선 배아 사용 여부',\n",
    "            '기증 배아 사용 여부',\n",
    "            '대리모 여부',\n",
    "            'PGD 시술 여부',\n",
    "            'PGS 시술 여부',\n",
    "            '난자 채취 경과일',\n",
    "            '난자 혼합 경과일',\n",
    "            '배아 이식 경과일',\n",
    "            '배아 해동 경과일',\n",
    "        ]\n",
    "    if value == 'mean':\n",
    "        imputer_mean = SimpleImputer(strategy='mean')\n",
    "        train[cols_to_numeric] = imputer_mean.fit_transform(train[cols_to_numeric])\n",
    "        test[cols_to_numeric] = imputer_mean.transform(test[cols_to_numeric])\n",
    "    elif value == 'median':\n",
    "        imputer_median = SimpleImputer(strategy='median')\n",
    "        train[cols_to_numeric] = imputer_median.fit_transform(train[cols_to_numeric])\n",
    "        test[cols_to_numeric] = imputer_median.transform(test[cols_to_numeric])\n",
    "    elif value == 'zero':\n",
    "        train[cols_to_numeric] = train[cols_to_numeric].fillna(0)\n",
    "        test[cols_to_numeric] = test[cols_to_numeric].fillna(0)\n",
    "    else:\n",
    "        train[cols_to_numeric] = train[cols_to_numeric].fillna(value).astype(float)\n",
    "        test[cols_to_numeric] = test[cols_to_numeric].fillna(value).astype(float)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def encoding(train, test, seed=42):\n",
    "    categorical_columns = [\n",
    "        \"시술 시기 코드\",\n",
    "        \"시술 당시 나이\",\n",
    "        \"배란 유도 유형\",\n",
    "        \"배아 생성 주요 이유\",\n",
    "\n",
    "        ## 시술 횟수\n",
    "        \"클리닉 내 총 시술 횟수\",\n",
    "        \"IVF 시술 횟수\",\n",
    "        \"DI 시술 횟수\",\n",
    "\n",
    "        ## 임신 횟수\n",
    "        \"총 임신 횟수\",\n",
    "        \"IVF 임신 횟수\",\n",
    "        \"DI 임신 횟수\",\n",
    "\n",
    "        ## 출산 횟수\n",
    "        \"총 출산 횟수\",\n",
    "        \"IVF 출산 횟수\",\n",
    "        \"DI 출산 횟수\",\n",
    "\n",
    "        \"난자 출처\",\n",
    "        \"정자 출처\",\n",
    "        \"난자 기증자 나이\",\n",
    "        \"정자 기증자 나이\",\n",
    "\n",
    "        '시술유형_통합', # 특정시술유형()\n",
    "    ]\n",
    "    train[categorical_columns] = train[categorical_columns].astype(str)\n",
    "    test[categorical_columns] = test[categorical_columns].astype(str)\n",
    "\n",
    "    train[categorical_columns] = train[categorical_columns].astype('category')\n",
    "    test[categorical_columns] = test[categorical_columns].astype('category')\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def num_feature_scailing(train, test):\n",
    "    cols_to_divide = [\n",
    "            '임신 시도 또는 마지막 임신 경과 연수',\n",
    "            '배란 자극 여부',\n",
    "            '단일 배아 이식 여부',\n",
    "            '착상 전 유전 검사 사용 여부',\n",
    "            '착상 전 유전 진단 사용 여부',\n",
    "            '총 생성 배아 수',\n",
    "            '미세주입된 난자 수',\n",
    "            '미세주입에서 생성된 배아 수',\n",
    "            '저장된 배아 수',\n",
    "            '미세주입 후 저장된 배아 수',\n",
    "            '해동된 배아 수',\n",
    "            '해동 난자 수',\n",
    "            '수집된 신선 난자 수',\n",
    "            '저장된 신선 난자 수',\n",
    "            '혼합된 난자 수',\n",
    "            '파트너 정자와 혼합된 난자 수',\n",
    "            '기증자 정자와 혼합된 난자 수',\n",
    "            '동결 배아 사용 여부',\n",
    "            '신선 배아 사용 여부',\n",
    "            '기증 배아 사용 여부',\n",
    "            '대리모 여부',\n",
    "            'PGD 시술 여부',\n",
    "            'PGS 시술 여부',\n",
    "        ]\n",
    "    # # 크기의 차이를 줄이기 위해서서\n",
    "    # train[cols_to_divide] = train[cols_to_divide] / 10\n",
    "    # test[cols_to_divide] = test[cols_to_divide] / 10\n",
    "\n",
    "    cols_to_log = [\n",
    "            '임신 시도 또는 마지막 임신 경과 연수',\n",
    "            '배란 자극 여부',\n",
    "            '단일 배아 이식 여부',\n",
    "            '착상 전 유전 검사 사용 여부',\n",
    "            '착상 전 유전 진단 사용 여부',\n",
    "            '총 생성 배아 수',\n",
    "            '미세주입된 난자 수',\n",
    "            '미세주입에서 생성된 배아 수',\n",
    "            '이식된 배아 수',\n",
    "            '미세주입 배아 이식 수',\n",
    "            '저장된 배아 수',\n",
    "            '미세주입 후 저장된 배아 수',\n",
    "            '해동된 배아 수',\n",
    "            '해동 난자 수',\n",
    "            '수집된 신선 난자 수',\n",
    "            '저장된 신선 난자 수',\n",
    "            '혼합된 난자 수',\n",
    "            '파트너 정자와 혼합된 난자 수',\n",
    "            '기증자 정자와 혼합된 난자 수',\n",
    "            '동결 배아 사용 여부',\n",
    "            '신선 배아 사용 여부',\n",
    "            '기증 배아 사용 여부',\n",
    "            '대리모 여부',\n",
    "            'PGD 시술 여부',\n",
    "            'PGS 시술 여부',\n",
    "            '난자 채취 경과일',\n",
    "            '난자 혼합 경과일',\n",
    "            '배아 이식 경과일',\n",
    "            '배아 해동 경과일',\n",
    "        ]\n",
    "    log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "    train[cols_to_log] = log_transformer.fit_transform(train[cols_to_log])\n",
    "    test[cols_to_log] = log_transformer.transform(test[cols_to_log])\n",
    "\n",
    "    numeric_cols = train.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    cat_cols = [col for col in train.columns if pd.api.types.is_categorical_dtype(train[col])]\n",
    "    cols_to_scale = [\n",
    "        col for col in numeric_cols\n",
    "        if col not in cat_cols and col != '임신 성공 여부'\n",
    "    ]\n",
    "    scaler = StandardScaler()\n",
    "    train[cols_to_scale] = scaler.fit_transform(train[cols_to_scale])\n",
    "    test[cols_to_scale] = scaler.transform(test[cols_to_scale])\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def all_process(train, test):\n",
    "    \n",
    "    train, test = drop_columns(train), drop_columns(test)\n",
    "\n",
    "    train, test = 특정시술유형(train, test)\n",
    "\n",
    "    train, test = 시술횟수(train), 시술횟수(test)\n",
    "    \n",
    "    # 카테고리 컬럼을 카테고리 타입으로 바꾸기\n",
    "    train, test = encoding(train, test)\n",
    "\n",
    "    # 결측값 0으로 채우기기\n",
    "    train, test = numeric_process(train, test, value='zero')\n",
    "\n",
    "    # 로그변환 후 정규화화\n",
    "    train, test = num_feature_scailing(train, test)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "# test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "####### 테스트로 적은 수의 데이터로##################\n",
    "train = train.sample(n=1000, random_state=42)\n",
    "###################################################\n",
    "\n",
    "# train 데이터의 label 컬럼을 기준으로 stratify 설정\n",
    "train, test = train_test_split(train, test_size=0.2, stratify=train['임신 성공 여부'], random_state=42)\n",
    "\n",
    "\n",
    "# train, test = all_process(train, test)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험 내용\n",
    "experiment_desc = '''\n",
    "WideDeep_TabMlp 임신 성공 여부 연속형 변수 임베딩\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# import scipy.special   # 시그모이드 대신 softmax에 사용할 수 있음\n",
    "# 교차 검증 설정: seed_list를 [333] 하나만 사용, n_splits=3\n",
    "seed_list = [333]\n",
    "n_splits = 5\n",
    "\n",
    "total_auc, total_acc, total_f1 = [], [], []\n",
    "test_preds = []\n",
    "\n",
    "# --- DataConfig 설정 ---\n",
    "# 범주형 변수 지정 (실제 데이터에 맞게 수정)\n",
    "categorical_cols = [\n",
    "        \"시술 시기 코드\",\n",
    "        \"시술 당시 나이\",\n",
    "        \"배란 유도 유형\",\n",
    "        \"배아 생성 주요 이유\",\n",
    "\n",
    "        ## 시술 횟수\n",
    "        \"클리닉 내 총 시술 횟수\",\n",
    "        \"IVF 시술 횟수\",\n",
    "        \"DI 시술 횟수\",\n",
    "\n",
    "        ## 임신 횟수\n",
    "        \"총 임신 횟수\",\n",
    "        \"IVF 임신 횟수\",\n",
    "        \"DI 임신 횟수\",\n",
    "\n",
    "        ## 출산 횟수\n",
    "        \"총 출산 횟수\",\n",
    "        \"IVF 출산 횟수\",\n",
    "        \"DI 출산 횟수\",\n",
    "\n",
    "        \"난자 출처\",\n",
    "        \"정자 출처\",\n",
    "        \"난자 기증자 나이\",\n",
    "        \"정자 기증자 나이\",\n",
    "\n",
    "        '시술유형_통합', # 특정시술유형()\n",
    "    ]  \n",
    "\n",
    "# 타겟과 범주형 변수 외 나머지를 연속형 변수로 처리 (실제 컬럼명에 맞게 수정)\n",
    "continuous_cols = [\n",
    "            '임신 시도 또는 마지막 임신 경과 연수',\n",
    "            '배란 자극 여부',\n",
    "            '단일 배아 이식 여부',\n",
    "            '착상 전 유전 검사 사용 여부',\n",
    "            '착상 전 유전 진단 사용 여부',\n",
    "            '총 생성 배아 수',\n",
    "            '미세주입된 난자 수',\n",
    "            '미세주입에서 생성된 배아 수',\n",
    "            '이식된 배아 수',\n",
    "            '미세주입 배아 이식 수',\n",
    "            '저장된 배아 수',\n",
    "            '미세주입 후 저장된 배아 수',\n",
    "            '해동된 배아 수',\n",
    "            '해동 난자 수',\n",
    "            '수집된 신선 난자 수',\n",
    "            '저장된 신선 난자 수',\n",
    "            '혼합된 난자 수',\n",
    "            '파트너 정자와 혼합된 난자 수',\n",
    "            '기증자 정자와 혼합된 난자 수',\n",
    "            '동결 배아 사용 여부',\n",
    "            '신선 배아 사용 여부',\n",
    "            '기증 배아 사용 여부',\n",
    "            '대리모 여부',\n",
    "            'PGD 시술 여부',\n",
    "            'PGS 시술 여부',\n",
    "            '난자 채취 경과일',\n",
    "            '난자 혼합 경과일',\n",
    "            '배아 이식 경과일',\n",
    "            '배아 해동 경과일',\n",
    "        ]\n",
    "\n",
    "# Wide 부분: 원-핫 인코딩 (crossed_cols 옵션도 사용할 수 있음)\n",
    "wide_cols = categorical_cols  # Wide 모델에는 범주형 변수를 원-핫 인코딩으로 처리\n",
    "crossed_cols = []  # 필요시 두 개 이상의 컬럼을 교차시켜 상호작용 feature 생성\n",
    "\n",
    "# WidePreprocessor (원-핫 인코딩, crossed_cols 사용 가능)\n",
    "wide_preprocessor = WidePreprocessor(wide_cols=wide_cols, crossed_cols=crossed_cols)\n",
    "\n",
    "# Deep 부분: 임베딩 + 연속형 변수 처리\n",
    "tab_preprocessor = TabPreprocessor(embed_cols=categorical_cols, continuous_cols=continuous_cols)\n",
    "\n",
    "\n",
    "\n",
    "# 교차 검증 시작\n",
    "for seed in seed_list:\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    auc_scores, acc_scores, f1_scores = [], [], []\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(train.drop(columns=['임신 성공 여부']), train[\"임신 성공 여부\"])):\n",
    "        # Fold 데이터 생성\n",
    "        fold_train, fold_valid = train.iloc[train_idx], train.iloc[valid_idx]\n",
    "        fold_train2 = fold_train.copy()\n",
    "        fold_test = test.copy()  # test 데이터는 별도 사용\n",
    "        \n",
    "        # 전처리 \n",
    "        fold_train, fold_valid = all_process(fold_train, fold_valid)\n",
    "        _, fold_test = all_process(fold_train2, fold_test)\n",
    "\n",
    "\n",
    "        # 전처리: 각 Fold 별로 Wide & Deep 데이터 생성\n",
    "        X_wide_train = wide_preprocessor.fit_transform(fold_train)\n",
    "        X_wide_valid = wide_preprocessor.transform(fold_valid)\n",
    "        X_wide_test = wide_preprocessor.transform(fold_test)\n",
    "        X_tab_train = tab_preprocessor.fit_transform(fold_train)\n",
    "        X_tab_valid = tab_preprocessor.transform(fold_valid)\n",
    "        X_tab_test = tab_preprocessor.transform(fold_test)\n",
    "\n",
    "        # Target 값: 정수형 (0,1)\n",
    "        y_train = fold_train['임신 성공 여부'].astype(int).values\n",
    "        y_valid = fold_valid['임신 성공 여부'].astype(int).values\n",
    "\n",
    "        # Wide 모델: 입력 차원은 원-핫 인코딩된 피처 수####\n",
    "        wide_model = Wide(input_dim=int(X_wide_train.max().item()), pred_dim=1)\n",
    "\n",
    "\n",
    "        # Deep 모델: TabMlp 사용\n",
    "        tab_model = TabMlp(\n",
    "            column_idx=tab_preprocessor.column_idx,  # 데이터 컬럼의 인덱스 정보 (필수)\n",
    "            cat_embed_input=tab_preprocessor.cat_embed_input,  # (컬럼명, 고유값 개수, 임베딩 차원) 리스트 (범주형 변수)\n",
    "            continuous_cols=continuous_cols,  # 연속형 변수 리스트\n",
    "            \n",
    "            # ▶ 범주형 임베딩 관련 파라미터 (Categorical Embeddings)\n",
    "            cat_embed_dropout=0.0,  # 범주형 변수의 임베딩 드롭아웃 확률 (기본값: 0.1)\n",
    "            use_cat_bias=False,  # 범주형 임베딩에 bias 추가 여부 (기본값: False)\n",
    "            cat_embed_activation=None,  # 범주형 임베딩의 활성화 함수 ('relu', 'tanh', 'leaky_relu', 'gelu' 가능, 기본값 없음)\n",
    "\n",
    "            # ▶ 연속형 변수 관련 파라미터 (Continuous Features)\n",
    "            cont_norm_layer='batchnorm',  # 연속형 변수 정규화 ('batchnorm' 또는 'layernorm', 기본값 없음)\n",
    "            embed_continuous_method='standard', # 연속형 변수 임베딩 방식\n",
    "            # 후보 값: 'standard' (기본), 'piecewise' (구간별 변환), 'periodic' (주기적 변환)\n",
    "\n",
    "            cont_embed_dim=8,  # 연속형 변수 임베딩 차원 (None이면 사용 안 함)\n",
    "            # 추천: 8~16 정도로 시작하고, 데이터가 복잡할수록 32 이상으로 증가 가능.\n",
    "\n",
    "            cont_embed_dropout=0.0,  # 연속형 변수 임베딩 드롭아웃 확률 (기본값: 0.0)\n",
    "            # 0.0 → 드롭아웃 사용 안 함 (데이터가 많거나 과적합 걱정이 없을 때)\n",
    "            # 0.1~0.3 → 적절한 정규화 효과 (일반적인 경우)\n",
    "            # 0.4 이상 → 데이터가 매우 적고 노이즈가 심할 때\n",
    "\n",
    "            cont_embed_activation='relu',  # 연속형 변수 임베딩 활성화 함수 (기본값 없음)\n",
    "            # ('relu', 'tanh', 'leaky_relu', 'gelu' 가능)\n",
    "\n",
    "            # ▶ MLP 관련 파라미터 (Multi-Layer Perceptron)\n",
    "            mlp_hidden_dims=[200, 100],  # MLP의 은닉층 크기 (기본값: [200, 100])\n",
    "            mlp_activation=\"relu\",  # MLP의 활성화 함수 ('relu', 'tanh', 'leaky_relu', 'gelu' 가능, 기본값: 'relu')\n",
    "            mlp_dropout=0.1,  # MLP 은닉층 드롭아웃 확률 (기본값: 0.1)\n",
    "            mlp_batchnorm=True,  # MLP의 배치 정규화 여부 (기본값: True)\n",
    "            mlp_batchnorm_last=False,  # MLP 마지막 층에도 배치 정규화 적용 여부 (기본값: False)\n",
    "            mlp_linear_first=True,  # 선형 변환을 먼저 적용할지 여부 (기본값: True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Wide & Deep 모델 결합\n",
    "        model = WideDeep(wide=wide_model, deeptabular=tab_model)\n",
    "        \n",
    "        # 옵티마이저 및 학습률 스케줄러 설정\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # Set your desired learning rate here\n",
    "        \n",
    "\n",
    "        # ✅ Training 데이터를 딕셔너리 형태로 생성\n",
    "        X_train = {\n",
    "            \"X_wide\": X_wide_train,\n",
    "            \"X_tab\": X_tab_train,\n",
    "            \"target\": y_train\n",
    "        }\n",
    "\n",
    "        # ✅ Validation 데이터를 딕셔너리로 전달 (X_val 방식 사용)\n",
    "        X_val = {\n",
    "            \"X_wide\": X_wide_valid,\n",
    "            \"X_tab\": X_tab_valid,\n",
    "            \"target\": y_valid\n",
    "        }\n",
    "        \n",
    "        # EarlyStopping 콜백 설정 (patience=5, min_delta=0.001)\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\", \n",
    "            patience=5, \n",
    "            min_delta=0.001, \n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # 현재 날짜/시간을 포함한 파일 이름 생성\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        model_path = f\"saved_models/best_model_{timestamp}.pt\"\n",
    "        \n",
    "        # ✅ 2. ModelCheckpoint: 최상의 모델을 자동 저장\n",
    "        model_checkpoint = ModelCheckpoint(\n",
    "            filepath=model_path,  # 모델 저장 경로\n",
    "            monitor=\"val_loss\",        # 감시할 지표 ('val_loss' 또는 'val_acc')\n",
    "            save_best_only=True        # 가장 좋은 성능의 모델만 저장\n",
    "        )\n",
    "        \n",
    "        # Trainer 생성: objective \"binary\"로 설정, 평가 지표로 Accuracy, AUROC, F1Score 사용\n",
    "        trainer = Trainer(\n",
    "            model=model, \n",
    "            objective=\"binary\", \n",
    "            custom_loss_function=None,  # 기본 손실 함수 사용 (필요 시 사용자 정의 함수 가능)\n",
    "            optimizers=optimizer,       # 옵티마이저 (기본값: Adam)\n",
    "            initializers=None,          # 가중치 초기화 없음 (기본값)\n",
    "            callbacks=[early_stopping],  # 조기 종료 (3 에포크 동안 개선 없으면 종료)\n",
    "            metrics=[Accuracy()],\n",
    "            verbose=1,                  # 학습 로그 출력 (기본값: 1)\n",
    "            seed=42                     # 랜덤 시드 설정 (기본값: 1)\n",
    "        )\n",
    "        \n",
    "        # 학습: validation 데이터는 별도의 인자로 전달\n",
    "        trainer.fit(\n",
    "            X_train=X_train,  # ✅ Training 데이터를 딕셔너리로 \n",
    "            n_epochs=100, \n",
    "            batch_size=128, \n",
    "            X_val=X_val  # ✅ Validation 데이터를 딕셔너리로 전달\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 모델 학습 후 Validation 예측 코드:\n",
    "        # 이미 확률이 계산되어 있는 컬럼을 사용합니다.\n",
    "        valid_probs = trainer.predict_proba(X_wide=X_wide_valid, X_tab=X_tab_valid)[:,1] ####\n",
    "        valid_pred = (valid_probs > 0.5).astype(int)\n",
    "\n",
    "        \n",
    "\n",
    "        # 실제 정답 \n",
    "        y_valid = fold_valid['임신 성공 여부'].values.astype(int)\n",
    "\n",
    "\n",
    "        \n",
    "        # 평가 지표 계산: 클래스 1의 확률 사용\n",
    "        fold_auc = roc_auc_score(y_valid, valid_probs)\n",
    "        fold_acc = accuracy_score(y_valid, valid_pred)\n",
    "        fold_f1 = f1_score(y_valid, valid_pred)\n",
    "        print(f\"Seed[{seed:<3}] Fold {fold + 1} | AUC: {fold_auc:.6f} | Acc: {fold_acc:.6f} | F1: {fold_f1:.6f}\")\n",
    "        \n",
    "        auc_scores.append(fold_auc)\n",
    "        acc_scores.append(fold_acc)\n",
    "        f1_scores.append(fold_f1)\n",
    "        \n",
    "        total_auc.append(fold_auc)\n",
    "        total_acc.append(fold_acc)\n",
    "        total_f1.append(fold_f1)\n",
    "        \n",
    "        # Test 데이터 예측 (각 fold의 모델로 예측한 결과 저장)\n",
    "        test_pred = trainer.predict_proba(X_wide=X_wide_test, X_tab=X_tab_test)[:,1]\n",
    "        test_preds.append(test_pred)\n",
    "    \n",
    "    # Fold 별 평균 성능 출력\n",
    "    avg_auc = np.mean(auc_scores)\n",
    "    avg_acc = np.mean(acc_scores)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Seed[{seed:<3}] Average Metrics | AUC: {avg_auc:.7f} | Acc: {avg_acc:.7f} | F1: {avg_f1:.7f}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# 전체 Validation 평균 성능 출력\n",
    "val_auc = np.mean(total_auc)\n",
    "val_acc = np.mean(total_acc)\n",
    "val_f1 = np.mean(total_f1)\n",
    "print(\"-\" * 80)\n",
    "print(f\"Validation Average Metrics | AUC: {val_auc:.7f} | Acc: {val_acc:.7f} | F1: {val_f1:.7f}\")\n",
    "\n",
    "finish_time = time.time()\n",
    "total_time = finish_time - start_time \n",
    "\n",
    "print(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratify_label = train[\"임신 성공 여부\"].astype(str)\n",
    "old_auc = 0.7289820 * 100\n",
    "old_acc = 0.7413351 * 100\n",
    "old_f1 = 0.2031272 * 100\n",
    "\n",
    "new_auc = val_auc * 100\n",
    "new_acc = val_acc * 100\n",
    "new_f1 = val_f1 * 100\n",
    "\n",
    "def calculate_change(old_value, new_value):\n",
    "    change = new_value - old_value\n",
    "    percentage_change = (change / old_value) * 100 if old_value != 0 else float('inf')\n",
    "    return change, percentage_change\n",
    "\n",
    "def format_change(change):\n",
    "    return f\"{change:+.6f}\"\n",
    "\n",
    "# 각 지표의 변화량 계산\n",
    "auc_change, auc_pct = calculate_change(old_auc, new_auc)\n",
    "acc_change, acc_pct = calculate_change(old_acc, new_acc)\n",
    "f1_change, f1_pct = calculate_change(old_f1, new_f1)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n================= 모델 성능 변화 =================\")\n",
    "print(f\"{'Metric':<8}  {'AUC':>12}  {'Acc':>12}  {'F1':>12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Old':<8}  {old_auc:>12.6f}  {old_acc:>12.6f}  {old_f1:>12.6f}\")\n",
    "print(f\"{'New':<8}  {new_auc:>12.6f}  {new_acc:>12.6f}  {new_f1:>12.6f}\")\n",
    "print(f\"{'Change':<8}  {format_change(auc_change):>12}  {format_change(acc_change):>12}  {format_change(f1_change):>12}\")\n",
    "print(f\"{'% Change':<8}  {auc_pct:>11.4f}%  {acc_pct:>11.4f}%  {f1_pct:>11.4f}%\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 활용 지표 계산\n",
    "# 평가 지표 계산: 클래스 1의 확률 사용\n",
    "\n",
    "test_auc = roc_auc_score(test['임신 성공 여부'], np.mean(test_preds, axis=0))\n",
    "print(f\"test 데이터 AUC: {test_auc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기본 test 데이터 AUC : 0.732737"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(sample_path)\n",
    "# test_preds\n",
    "# sample_submission['임신 성공 확률'] = np.mean(test_preds, axis=0)\n",
    "\n",
    "# ratio = train['임신 성공 여부'].value_counts(normalize=True)[1]\n",
    "# real_true_count = int(ratio * len(sample_submission))\n",
    "# print(f'test의 True 갯수: {real_true_count:<5} (추정)')\n",
    "\n",
    "# count = (sample_submission['임신 성공 확률'] >= 0.5).sum()\n",
    "# print(f'test의 True 갯수: {count:<5} (예측 결과)')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now().strftime(\"%m%d_%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = 'Submission'\n",
    "if not os.path.exists(submission_path):\n",
    "    os.makedirs(submission_path)\n",
    "\n",
    "code_dir = 'Code'\n",
    "if not os.path.exists(code_dir):\n",
    "    os.makedirs(code_dir)\n",
    "\n",
    "\n",
    "submission_name = f\"submission_{now}.csv\"\n",
    "new_notebook_name = f\"code_{now}.ipynb\"\n",
    "\n",
    "sample_submission.to_csv(os.path.join(submission_path, submission_name), index=False)\n",
    "\n",
    "\n",
    "# 현재 노트북 파일 경로 직접 지정 (실제 노트북 파일명으로 수정)\n",
    "current_notebook = os.path.join(os.getcwd(), \"WideDeep_TabMlp_임신 여부.ipynb\")\n",
    "\n",
    "new_notebook_path = os.path.join(code_dir, new_notebook_name)\n",
    "\n",
    "# 노트북 파일 복사\n",
    "shutil.copy(current_notebook, new_notebook_path)\n",
    "\n",
    "print(f\"Notebook saved in '{code_dir}' as '{new_notebook_name}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 SQLite 데이터베이스 설정\n",
    "db_path = \"experiment_results.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 📌 테이블 생성 (처음 실행 시)\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS experiments (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    code_name TEXT,\n",
    "    experiment_desc TEXT,\n",
    "    auc REAL,\n",
    "    acc REAL,\n",
    "    f1 REAL\n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 삽입\n",
    "cursor.execute('''\n",
    "INSERT INTO experiments (code_name, experiment_desc, auc, acc, f1)\n",
    "VALUES (?, ?, ?, ?, ?)\n",
    "''', (new_notebook_name, experiment_desc.strip(), new_auc, new_acc, new_f1))\n",
    "\n",
    "# 변경사항 저장 & 연결 종료\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(f\"Experiment '{new_notebook_name}' successfully saved in database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# SQLite 데이터 조회 함수\n",
    "def get_experiment_results(db_path=\"experiment_results.db\", num_results=10):\n",
    "    \"\"\"\n",
    "    SQLite 데이터베이스에서 중복된 실험 데이터를 제거하고, 최근 num_results개의 실험 데이터를 불러오는 함수.\n",
    "    Returns:\n",
    "        - Pandas DataFrame: 중복 제거된 실험 데이터\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    # 중복 제거 & 최신 데이터 선택하는 SQL 쿼리\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM experiments\n",
    "    WHERE id IN (\n",
    "        SELECT MAX(id)  -- 가장 최신 데이터 선택\n",
    "        FROM experiments\n",
    "        GROUP BY code_name -- id 제외하고 중복 판단\n",
    "    )\n",
    "    ORDER BY id DESC  -- 최신 데이터부터 정렬\n",
    "    LIMIT {num_results};\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = get_experiment_results(num_results=100)\n",
    "df_results.to_csv('experiment_results.csv', index=False, encoding='utf-8-sig', float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg2025",
   "language": "python",
   "name": "lg2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
