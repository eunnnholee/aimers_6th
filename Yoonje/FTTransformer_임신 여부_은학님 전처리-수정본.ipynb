{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FTTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:04:09.458457Z",
     "start_time": "2025-03-30T14:04:09.455457Z"
    }
   },
   "source": [
    "# !pip install numpy==1.26.0\n",
    "# !pip install pandas==2.2.2\n",
    "# !pip install scikit-learn==1.5.1\n",
    "# !pip install scipy==1.14.1\n",
    "# !pip install statsmodels==0.14.2\n",
    "# !pip install joblib==1.4.2\n",
    "# !pip install threadpoolctl==3.5.0\n",
    "# !pip install ipynbname"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:04:09.504446Z",
     "start_time": "2025-03-30T14:04:09.461455Z"
    }
   },
   "source": [
    "# # 1. ê¸°ì¡´ì˜ íŒ¨í‚¤ì§€ ì •ë¦¬\n",
    "# !pip uninstall -y torch torchvision torchaudio pytorch-lightning pytorch-tabular\n",
    "\n",
    "# # 2. í˜¸í™˜ ê°€ëŠ¥í•œ ë²„ì „ìœ¼ë¡œ ì¬ì„¤ì¹˜\n",
    "# !pip install torch==2.0.1+cu118 --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip install pytorch-tabular==1.1.1 --no-deps\n",
    "# !pip install pytorch-lightning==2.0.0"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:04:09.567460Z",
     "start_time": "2025-03-30T14:04:09.552462Z"
    }
   },
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:04:09.599460Z",
     "start_time": "2025-03-30T14:04:09.584461Z"
    }
   },
   "source": [
    "# !pip install \"pytorch_tabular[extra]\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:04:31.699911Z",
     "start_time": "2025-03-30T14:04:31.686045Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import shutil\n",
    "import ipynbname\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, FunctionTransformer, QuantileTransformer, MultiLabelBinarizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import pytorch_tabular\n",
    "\n",
    "# PyTorch Tabular ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import FTTransformerConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    ")\n",
    "\n",
    "##################\n",
    "data_seed=7\n",
    "\n",
    "train_path = f'../data/custom_train_{data_seed}.csv'\n",
    "test_path = f'../data/custom_test_{data_seed}.csv'"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:04:33.496600Z",
     "start_time": "2025-03-30T14:04:32.650484Z"
    }
   },
   "source": [
    "train = pd.read_csv(train_path).drop(columns=[\"ID\"])\n",
    "test = pd.read_csv(test_path).drop(columns=[\"ID\"])\n",
    "print(train.shape, test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205080, 68) (51271, 67)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:04:41.026687Z",
     "start_time": "2025-03-30T14:04:40.997687Z"
    }
   },
   "source": [
    "def drop_columns(df):\n",
    "    cols = [\n",
    "        'ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸',  # ê³ ìœ ê°’ 1\n",
    "        'ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸',  # train, test ëª¨ë‘ '1'ì¸ ë°ì´í„° 1ê°œ >> ì‹ ë¢°í•  ìˆ˜ ì—†ìŒ\n",
    "        'ë‚œì í•´ë™ ê²½ê³¼ì¼',\n",
    "    ]\n",
    "    df = df.drop(cols, axis=1)\n",
    "    return df\n",
    "\n",
    "def íŠ¹ì •ì‹œìˆ ìœ í˜•(train, test):\n",
    "    def categorize_procedure(proc):\n",
    "        tokens = [token.strip() for token in proc.split(\",\") if token.strip() and not token.strip().isdigit()]\n",
    "        # ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ë²”ì£¼í™”\n",
    "        if tokens.count(\"Unknown\") >= 1:\n",
    "            return \"Unknown\"\n",
    "        if tokens.count(\"AH\") >= 1:\n",
    "            return \"AH\"\n",
    "        if tokens.count(\"BLASTOCYST\") >= 1:\n",
    "            return \"BLASTOCYST\"\n",
    "        if tokens.count(\"ICSI\") >= 2 or tokens.count(\"IVF\") >= 2:\n",
    "            return \"2ICSI_2IVF\"\n",
    "        if tokens.count(\"IVF\") >= 1 and tokens.count(\"ICSI\") >= 1:\n",
    "            return \"IVF_ICSI\"\n",
    "        if tokens == \"ICSI\":\n",
    "            return \"ICSI\"\n",
    "        if tokens == \"IVF\":\n",
    "            return \"IVF\"\n",
    "        return \",\".join(tokens) if tokens else None\n",
    "\n",
    "    for df in [train, test]:\n",
    "        df['íŠ¹ì • ì‹œìˆ  ìœ í˜•'] = df['íŠ¹ì • ì‹œìˆ  ìœ í˜•'].str.replace(\" / \", \",\")\n",
    "        df['íŠ¹ì • ì‹œìˆ  ìœ í˜•'] = df['íŠ¹ì • ì‹œìˆ  ìœ í˜•'].str.replace(\":\", \",\")\n",
    "        df['íŠ¹ì • ì‹œìˆ  ìœ í˜•'] = df['íŠ¹ì • ì‹œìˆ  ìœ í˜•'].str.replace(\" \", \"\")\n",
    "\n",
    "    counts = train['íŠ¹ì • ì‹œìˆ  ìœ í˜•'].value_counts()\n",
    "    allowed_categories = counts[counts >= 100].index.tolist()\n",
    "\n",
    "    # allowed_categoriesì— ì†í•˜ì§€ ì•ŠëŠ” ê°’ì€ \"Unknown\"ìœ¼ë¡œ ëŒ€ì²´\n",
    "    train.loc[~train['íŠ¹ì • ì‹œìˆ  ìœ í˜•'].isin(allowed_categories), 'íŠ¹ì • ì‹œìˆ  ìœ í˜•'] = \"Unknown\"\n",
    "    test.loc[~test['íŠ¹ì • ì‹œìˆ  ìœ í˜•'].isin(allowed_categories), 'íŠ¹ì • ì‹œìˆ  ìœ í˜•'] = \"Unknown\"\n",
    "\n",
    "    train['íŠ¹ì • ì‹œìˆ  ìœ í˜•'] = train['íŠ¹ì • ì‹œìˆ  ìœ í˜•'].apply(categorize_procedure)\n",
    "    test['íŠ¹ì • ì‹œìˆ  ìœ í˜•'] = test['íŠ¹ì • ì‹œìˆ  ìœ í˜•'].apply(categorize_procedure)\n",
    "\n",
    "    train['ì‹œìˆ ìœ í˜•_í†µí•©'] = train['ì‹œìˆ  ìœ í˜•'].astype(str) + '_' + train['íŠ¹ì • ì‹œìˆ  ìœ í˜•'].astype(str)\n",
    "    test['ì‹œìˆ ìœ í˜•_í†µí•©'] = test['ì‹œìˆ  ìœ í˜•'].astype(str) + '_' + test['íŠ¹ì • ì‹œìˆ  ìœ í˜•'].astype(str)\n",
    "\n",
    "    drop_cols = ['ì‹œìˆ  ìœ í˜•', 'íŠ¹ì • ì‹œìˆ  ìœ í˜•']\n",
    "    train = train.drop(drop_cols, axis=1)\n",
    "    test = test.drop(drop_cols, axis=1)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def ì‹œìˆ íšŸìˆ˜(df_train):\n",
    "    for col in [col for col in df_train.columns if 'íšŸìˆ˜' in col]:\n",
    "        df_train[col] = df_train[col].replace({'6íšŒ ì´ìƒ':'6íšŒ'})\n",
    "        df_train[col] = df_train[col].str[0].astype(int)\n",
    "    df_train['ì‹œìˆ _ì„ì‹ '] = df_train['ì´ ì„ì‹  íšŸìˆ˜'] - df_train['ì´ ì‹œìˆ  íšŸìˆ˜']\n",
    "    df_train = df_train.drop('ì´ ì‹œìˆ  íšŸìˆ˜', axis=1)\n",
    "    return df_train\n",
    "\n",
    "def ë°°ë€ìœ ë„ìœ í˜•(df_train, df_test):\n",
    "    mapping = {\n",
    "        'ê¸°ë¡ë˜ì§€ ì•Šì€ ì‹œí–‰': 1,\n",
    "        'ì•Œ ìˆ˜ ì—†ìŒ': 0,\n",
    "        'ì„¸íŠ¸ë¡œíƒ€ì´ë“œ (ì–µì œì œ)': 0,\n",
    "        'ìƒì‹ì„  ìê·¹ í˜¸ë¥´ëª¬': 0,\n",
    "    }\n",
    "    df_train['ë°°ë€ ìœ ë„ ìœ í˜•'] = df_train['ë°°ë€ ìœ ë„ ìœ í˜•'].replace(mapping)\n",
    "    df_test['ë°°ë€ ìœ ë„ ìœ í˜•'] = df_test['ë°°ë€ ìœ ë„ ìœ í˜•'].replace(mapping)\n",
    "    return df_train, df_test\n",
    "\n",
    "def ë‚œìê¸°ì¦ìë‚˜ì´(df_train, df_test):\n",
    "    mapping = {\n",
    "        'ë§Œ20ì„¸ ì´í•˜': 20,\n",
    "        'ë§Œ21-25ì„¸': 25,\n",
    "        'ë§Œ26-30ì„¸': 30,\n",
    "        'ë§Œ31-35ì„¸': 35,\n",
    "        'ì•Œ ìˆ˜ ì—†ìŒ': 20,  # ë§Œ20ì„¸ ì´í•˜ì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬\n",
    "    }\n",
    "    df_train['ë‚œì ê¸°ì¦ì ë‚˜ì´'] = df_train['ë‚œì ê¸°ì¦ì ë‚˜ì´'].replace(mapping)\n",
    "    df_test['ë‚œì ê¸°ì¦ì ë‚˜ì´'] = df_test['ë‚œì ê¸°ì¦ì ë‚˜ì´'].replace(mapping)\n",
    "    return df_train, df_test\n",
    "\n",
    "def ë°°ì•„ìƒì„±ì£¼ìš”ì´ìœ (df_train, df_test):\n",
    "    df_train['ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ '] = df_train['ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ '].fillna('DI')\n",
    "    df_test['ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ '] = df_test['ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ '].fillna('DI')\n",
    "\n",
    "    df_train['ë°°ì•„ ìƒì„± ì´ìœ  ë¦¬ìŠ¤íŠ¸'] = df_train['ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ '].apply(lambda x: [reason.strip() for reason in x.split(',')])\n",
    "    df_test['ë°°ì•„ ìƒì„± ì´ìœ  ë¦¬ìŠ¤íŠ¸'] = df_test['ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ '].apply(lambda x: [reason.strip() for reason in x.split(',')])\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    train_one_hot = pd.DataFrame(\n",
    "        mlb.fit_transform(df_train['ë°°ì•„ ìƒì„± ì´ìœ  ë¦¬ìŠ¤íŠ¸']),\n",
    "        columns=mlb.classes_,\n",
    "        index=df_train.index\n",
    "    )\n",
    "    train_one_hot.columns = ['ë°°ì•„ìƒì„±ì´ìœ _' + col for col in train_one_hot.columns]\n",
    "\n",
    "    test_one_hot = pd.DataFrame(\n",
    "        mlb.transform(df_test['ë°°ì•„ ìƒì„± ì´ìœ  ë¦¬ìŠ¤íŠ¸']),\n",
    "        columns=mlb.classes_,\n",
    "        index=df_test.index\n",
    "    )\n",
    "    test_one_hot.columns = ['ë°°ì•„ìƒì„±ì´ìœ _' + col for col in test_one_hot.columns]\n",
    "\n",
    "    df_train = pd.concat([df_train, train_one_hot], axis=1)\n",
    "    df_test = pd.concat([df_test, test_one_hot], axis=1)\n",
    "\n",
    "    cols_to_drop = [\n",
    "        'ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ',\n",
    "        'ë°°ì•„ ìƒì„± ì´ìœ  ë¦¬ìŠ¤íŠ¸',\n",
    "        'ë°°ì•„ìƒì„±ì´ìœ _ì—°êµ¬ìš©',\n",
    "        'ë°°ì•„ìƒì„±ì´ìœ _DI'\n",
    "    ]\n",
    "    df_train = df_train.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "    df_test = df_test.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "    cols = ['ë°°ì•„ìƒì„±ì´ìœ _ê¸°ì¦ìš©',\n",
    "            'ë°°ì•„ìƒì„±ì´ìœ _ë‚œì ì €ì¥ìš©',\n",
    "            'ë°°ì•„ìƒì„±ì´ìœ _ë°°ì•„ ì €ì¥ìš©',\n",
    "            'ë°°ì•„ìƒì„±ì´ìœ _í˜„ì¬ ì‹œìˆ ìš©']\n",
    "\n",
    "    df_train[cols] = df_train[cols].div(df_train[cols].sum(axis=1).replace(0, np.nan), axis=0).fillna(0)\n",
    "    df_test[cols] = df_test[cols].div(df_test[cols].sum(axis=1).replace(0, np.nan), axis=0).fillna(0)\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "def ë‹¨ì¼ë°°ì•„ì´ì‹ì—¬ë¶€(df_train, df_val):\n",
    "    df_train['ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€'] = df_train['ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€'].fillna(0)\n",
    "    df_val['ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€'] = df_val['ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€'].fillna(0)\n",
    "    return df_train, df_val\n",
    "\n",
    "\n",
    "def ê¸°ì¦ìì •ìì™€í˜¼í•©ëœë‚œììˆ˜(df_train, df_test):\n",
    "    df_train[\"ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\"] = df_train[\"ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\"].fillna(2)\n",
    "    df_test[\"ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\"] = df_test[\"ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\"].fillna(2)\n",
    "    return df_train, df_test\n",
    "\n",
    "def label_encoding(train, test, cols):\n",
    "    encoder = LabelEncoder()\n",
    "    for col in cols:\n",
    "        train[col] = encoder.fit_transform(train[col])\n",
    "        test[col] = encoder.transform(test[col])\n",
    "    return train, test\n",
    "\n",
    "def type_to_category(train, test, cols):\n",
    "    train[cols] = train[cols].astype('category')\n",
    "    test[cols] = test[cols].astype('category')\n",
    "    return train, test\n",
    "\n",
    "def impute_nan(train, test):\n",
    "    cols_to_impute = [\n",
    "        'ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜', # DI, IVFë‘ ê´€ë ¨ X\n",
    "    ]\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    train[cols_to_impute] = imputer.fit_transform(train[cols_to_impute])\n",
    "    test[cols_to_impute] = imputer.transform(test[cols_to_impute])\n",
    "\n",
    "    cols_to_impute = [\n",
    "        'ë‚œì ì±„ì·¨ ê²½ê³¼ì¼',\n",
    "        'ë‚œì í˜¼í•© ê²½ê³¼ì¼',\n",
    "        'ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼',\n",
    "        'ë°°ì•„ í•´ë™ ê²½ê³¼ì¼',\n",
    "\n",
    "        'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€',\n",
    "        'PGD ì‹œìˆ  ì—¬ë¶€',\n",
    "        'PGS ì‹œìˆ  ì—¬ë¶€',\n",
    "\n",
    "        ### DI only\n",
    "        'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€',\n",
    "        'ì´ ìƒì„± ë°°ì•„ ìˆ˜',\n",
    "        'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜',\n",
    "        'ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜',\n",
    "        'ì´ì‹ëœ ë°°ì•„ ìˆ˜',\n",
    "        'ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜',\n",
    "        'ì €ì¥ëœ ë°°ì•„ ìˆ˜',\n",
    "        'ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜',\n",
    "        'í•´ë™ëœ ë°°ì•„ ìˆ˜',\n",
    "        'í•´ë™ ë‚œì ìˆ˜',\n",
    "        'ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜',\n",
    "        'ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜',\n",
    "        'í˜¼í•©ëœ ë‚œì ìˆ˜',\n",
    "        'íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜',\n",
    "        'ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜',\n",
    "        'ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€',\n",
    "        'ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€',\n",
    "        'ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€',\n",
    "        'ëŒ€ë¦¬ëª¨ ì—¬ë¶€',\n",
    "        ### DI\n",
    "    ]\n",
    "    train[cols_to_impute] = train[cols_to_impute].fillna(0)\n",
    "    test[cols_to_impute] = test[cols_to_impute].fillna(0)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def num_feature_scailing(train, test, seed=777):\n",
    "    numeric_cols = train.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    cat_cols = [col for col in train.columns if pd.api.types.is_categorical_dtype(train[col])]\n",
    "    cols_to_scale = [\n",
    "        col for col in numeric_cols\n",
    "        if col not in cat_cols and col != 'ì„ì‹  ì„±ê³µ ì—¬ë¶€'\n",
    "    ]\n",
    "\n",
    "    arr_train = train[cols_to_scale].to_numpy()  # DataFrame -> NumPy\n",
    "    arr_train = arr_train.astype(np.float32)\n",
    "    arr_test = test[cols_to_scale].to_numpy()\n",
    "    arr_test = arr_test.astype(np.float32)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    noise = (\n",
    "        np.random.default_rng(0)\n",
    "        .normal(0.0, 1e-5, arr_train.shape)\n",
    "        .astype(arr_train.dtype)\n",
    "    )\n",
    "    preprocessing = QuantileTransformer(\n",
    "        n_quantiles=max(min(len(train[cols_to_scale]) // 30, 1000), 10),\n",
    "        output_distribution='normal',\n",
    "        subsample=10**9,\n",
    "    ).fit(arr_train + noise)\n",
    "\n",
    "    # train[cols_to_scale] = preprocessing.transform(arr_train + noise)\n",
    "    train[cols_to_scale] = preprocessing.transform(arr_train)\n",
    "    test[cols_to_scale] = preprocessing.transform(arr_test)\n",
    "    return train, test\n",
    "\n",
    "def drop_single_value_columns(df_train, df_test):\n",
    "    cols_to_drop = [col for col in df_train.columns if df_train[col].nunique() == 1]\n",
    "    return df_train.drop(columns=cols_to_drop), df_test.drop(columns=cols_to_drop)\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:04:51.894145Z",
     "start_time": "2025-03-30T14:04:47.478908Z"
    }
   },
   "source": [
    "def all_process(train, val):\n",
    "    # ê¸°ë³¸ ì „ì²˜ë¦¬ ë‹¨ê³„\n",
    "    train, val = drop_columns(train), drop_columns(val)\n",
    "    train, val = íŠ¹ì •ì‹œìˆ ìœ í˜•(train, val)\n",
    "    train, val = ì‹œìˆ íšŸìˆ˜(train), ì‹œìˆ íšŸìˆ˜(val)\n",
    "\n",
    "    train, val = ë‹¨ì¼ë°°ì•„ì´ì‹ì—¬ë¶€(train, val)\n",
    "    train, val = ë°°ë€ìœ ë„ìœ í˜•(train, val)\n",
    "    train, val = ë°°ì•„ìƒì„±ì£¼ìš”ì´ìœ (train, val)\n",
    "\n",
    "    cols_to_encoding = [\n",
    "        \"ì‹œìˆ  ì‹œê¸° ì½”ë“œ\",\n",
    "        \"ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´\",\n",
    "        \"ë°°ë€ ìœ ë„ ìœ í˜•\",\n",
    "        # \"í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜\",\n",
    "        # \"IVF ì‹œìˆ  íšŸìˆ˜\",\n",
    "        # \"DI ì‹œìˆ  íšŸìˆ˜\",\n",
    "        # \"ì´ ì„ì‹  íšŸìˆ˜\",\n",
    "        # \"IVF ì„ì‹  íšŸìˆ˜\",\n",
    "        # \"DI ì„ì‹  íšŸìˆ˜\",\n",
    "        # \"ì´ ì¶œì‚° íšŸìˆ˜\",\n",
    "        # \"IVF ì¶œì‚° íšŸìˆ˜\",\n",
    "        # \"DI ì¶œì‚° íšŸìˆ˜\",\n",
    "        \"ë‚œì ì¶œì²˜\",\n",
    "        \"ì •ì ì¶œì²˜\",\n",
    "        \"ë‚œì ê¸°ì¦ì ë‚˜ì´\",\n",
    "        \"ì •ì ê¸°ì¦ì ë‚˜ì´\",\n",
    "        'ì‹œìˆ ìœ í˜•_í†µí•©',\n",
    "    ]\n",
    "    train, val = label_encoding(train, val, cols=cols_to_encoding)\n",
    "    train, val = type_to_category(train, val, cols=cols_to_encoding)\n",
    "\n",
    "    train, val = impute_nan(train, val)\n",
    "    train, val = num_feature_scailing(train, val)\n",
    "\n",
    "    train, val = drop_single_value_columns(train, val)\n",
    "\n",
    "    return train, val\n",
    "\n",
    "train = pd.read_csv(train_path).drop(columns=[\"ID\"])\n",
    "test = pd.read_csv(test_path).drop(columns=[\"ID\"])\n",
    "\n",
    "train, test = all_process(train, test)\n",
    "\n",
    "cat_cols = [col for col in train.columns if pd.api.types.is_categorical_dtype(train[col])]\n",
    "numeric_cols = [col for col in train.columns if col not in cat_cols and col != 'ì„ì‹  ì„±ê³µ ì—¬ë¶€']\n",
    "\n",
    "print(f'ìˆ˜ì¹˜í˜• ë³€ìˆ˜: {len(numeric_cols)}ê°œ \\n{numeric_cols}')\n",
    "print(f'ë²”ì£¼í˜• ë³€ìˆ˜: {len(cat_cols)}ê°œ \\n{cat_cols}')\n",
    "print(train.shape, test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìˆ˜ì¹˜í˜• ë³€ìˆ˜: 57ê°œ \n",
      "['ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜', 'ë°°ë€ ìê·¹ ì—¬ë¶€', 'ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', 'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€', 'ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸', 'ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸', 'ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸', 'ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸', 'ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸', 'ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜', 'ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸', 'ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• ', 'ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ', 'ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦', 'ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„', 'ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±', 'ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ', 'í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜', 'IVF ì‹œìˆ  íšŸìˆ˜', 'DI ì‹œìˆ  íšŸìˆ˜', 'ì´ ì„ì‹  íšŸìˆ˜', 'IVF ì„ì‹  íšŸìˆ˜', 'DI ì„ì‹  íšŸìˆ˜', 'ì´ ì¶œì‚° íšŸìˆ˜', 'IVF ì¶œì‚° íšŸìˆ˜', 'DI ì¶œì‚° íšŸìˆ˜', 'ì´ ìƒì„± ë°°ì•„ ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜', 'ì´ì‹ëœ ë°°ì•„ ìˆ˜', 'ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜', 'ì €ì¥ëœ ë°°ì•„ ìˆ˜', 'ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜', 'í•´ë™ëœ ë°°ì•„ ìˆ˜', 'í•´ë™ ë‚œì ìˆ˜', 'ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜', 'ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜', 'í˜¼í•©ëœ ë‚œì ìˆ˜', 'íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜', 'ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜', 'ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€', 'ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€', 'ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€', 'ëŒ€ë¦¬ëª¨ ì—¬ë¶€', 'PGD ì‹œìˆ  ì—¬ë¶€', 'PGS ì‹œìˆ  ì—¬ë¶€', 'ë‚œì í˜¼í•© ê²½ê³¼ì¼', 'ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼', 'ë°°ì•„ í•´ë™ ê²½ê³¼ì¼', 'ì‹œìˆ _ì„ì‹ ', 'ë°°ì•„ìƒì„±ì´ìœ _ê¸°ì¦ìš©', 'ë°°ì•„ìƒì„±ì´ìœ _ë‚œì ì €ì¥ìš©', 'ë°°ì•„ìƒì„±ì´ìœ _ë°°ì•„ ì €ì¥ìš©', 'ë°°ì•„ìƒì„±ì´ìœ _í˜„ì¬ ì‹œìˆ ìš©']\n",
      "ë²”ì£¼í˜• ë³€ìˆ˜: 8ê°œ \n",
      "['ì‹œìˆ  ì‹œê¸° ì½”ë“œ', 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´', 'ë°°ë€ ìœ ë„ ìœ í˜•', 'ë‚œì ì¶œì²˜', 'ì •ì ì¶œì²˜', 'ë‚œì ê¸°ì¦ì ë‚˜ì´', 'ì •ì ê¸°ì¦ì ë‚˜ì´', 'ì‹œìˆ ìœ í˜•_í†µí•©']\n",
      "(205080, 66) (51271, 65)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:04:55.048414Z",
     "start_time": "2025-03-30T14:04:55.033415Z"
    }
   },
   "source": [
    "# ì‹¤í—˜ ë‚´ìš©\n",
    "experiment_desc = '''\n",
    "FTTransformerConfig ì„ì‹  ì„±ê³µ ì—¬ë¶€ input_embed_dim 32â†’ 16, \n",
    "'''"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:01:13.482605Z",
     "start_time": "2025-03-30T15:01:13.469195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TrainerConfig: ì—¬ê¸°ì„œ ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=False, # ìë™ìœ¼ë¡œ í•™ìŠµë¥  ì°¾ê¸° ####\n",
    "    batch_size=1024,  # ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì„¤ì • #####\n",
    "    max_epochs=100,  # ë„‰ë„‰í•˜ê²Œ ì„¤ì •\n",
    "    early_stopping=\"valid_loss\",  # validation loss ê¸°ì¤€\n",
    "    early_stopping_mode=\"min\",  # ìµœì†Œí™”í•  ë•Œ ë©ˆì¶¤\n",
    "    early_stopping_patience=3,  # ê°œì„ ì´ ì—†ì„ ë•Œ 5 ì—í¬í¬ í›„ ë©ˆì¶¤\n",
    "    progress_bar='simple',\n",
    ")\n",
    "\n",
    "# --- OptimizerConfig ì„¤ì • ---\n",
    "optimizer_config = OptimizerConfig(\n",
    "    # optimizer=\"Adam\",\n",
    "    # optimizer_params={\"weight_decay\": 1e-5},\n",
    "    # # weight_decay ê°€ì¤‘ì¹˜ ê°ì†Œì˜ ê°•ë„ë¥¼ ì„¤ì •í•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ->  ê°€ì¤‘ì¹˜ê°€ ë„ˆë¬´ ì»¤ì§€ì§€ ì•Šë„ë¡ ì œì–´\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:01:30.582904700Z",
     "start_time": "2025-03-30T15:01:15.239681Z"
    }
   },
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# êµì°¨ ê²€ì¦ ì„¤ì •: seed_listë¥¼ [333] í•˜ë‚˜ë§Œ ì‚¬ìš©, n_splits=3\n",
    "seed_list = [333]\n",
    "n_splits = 5\n",
    "\n",
    "total_auc, total_acc, total_f1 = [], [], []\n",
    "test_preds = []\n",
    "\n",
    "# êµì°¨ ê²€ì¦ ì‹œì‘\n",
    "for seed in seed_list:\n",
    "    # train, test ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    train = pd.read_csv(train_path).drop(columns=[\"ID\"])\n",
    "    test = pd.read_csv(test_path).drop(columns=[\"ID\"])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    auc_scores, acc_scores, f1_scores = [], [], []\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(train.drop(columns=['ì„ì‹  ì„±ê³µ ì—¬ë¶€']), train[\"ì„ì‹  ì„±ê³µ ì—¬ë¶€\"])):\n",
    "        # Fold ë°ì´í„° ìƒì„±\n",
    "        fold_train, fold_valid = train.iloc[train_idx], train.iloc[valid_idx]\n",
    "        fold_train2 = fold_train.copy()\n",
    "        fold_test = test.copy()  # test ë°ì´í„°ëŠ” ë³„ë„ ì‚¬ìš©\n",
    "        \n",
    "        # ì „ì²˜ë¦¬ \n",
    "        fold_train, fold_valid = all_process(fold_train, fold_valid)\n",
    "        _, fold_test = all_process(fold_train2, fold_test)\n",
    "\n",
    "        categorical_cols = [col for col in fold_train.columns if pd.api.types.is_categorical_dtype(fold_train[col])]\n",
    "        continuous_cols = [col for col in fold_train.columns if col not in cat_cols and col != 'ì„ì‹  ì„±ê³µ ì—¬ë¶€']\n",
    "        data_config = DataConfig(\n",
    "            target=['ì„ì‹  ì„±ê³µ ì—¬ë¶€'],\n",
    "            continuous_cols=continuous_cols,\n",
    "            categorical_cols=categorical_cols,\n",
    "        )\n",
    "\n",
    "\n",
    "        model_config = FTTransformerConfig(\n",
    "            task=\"classification\",\n",
    "            input_embed_dim=16,  # ì…ë ¥ ë²”ì£¼í˜• íŠ¹ì„±ì— ëŒ€í•œ ì„ë² ë”© ì°¨ì›ì„ ì„¤ì •\n",
    "            num_heads=8,  # ë©€í‹°í—¤ë“œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì—ì„œ ì‚¬ìš©í•  ì–´í…ì…˜ í—¤ë“œì˜ ìˆ˜\n",
    "            num_attn_blocks=6,  # Transformer ë ˆì´ì–´(ë˜ëŠ” ë¸”ë¡)ì˜ ìˆ˜\n",
    "            attn_dropout=0.1,  # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì— ì ìš©í•  ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨\n",
    "            ff_dropout=0.1,  # í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ì— ì ìš©í•  ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨\n",
    "            learning_rate=1e-3,  # í•™ìŠµë¥ \n",
    "            metrics=[\"auroc\"],\n",
    "            metrics_prob_input=[True],\n",
    "            seed=seed,\n",
    "        )\n",
    "\n",
    "        model = TabularModel(\n",
    "            model_config=model_config,\n",
    "            data_config=data_config,\n",
    "            optimizer_config=optimizer_config,\n",
    "            trainer_config=trainer_config,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "\n",
    "        # ëª¨ë¸ í•™ìŠµ (í•„ìš”ì— ë”°ë¼ ì¡°ì •)\n",
    "        model.fit(train=fold_train,\n",
    "                  validation=fold_valid,\n",
    "                  seed=seed)\n",
    "        \n",
    "\n",
    "        \n",
    "        # ëª¨ë¸ í•™ìŠµ í›„ Validation ì˜ˆì¸¡ ì½”ë“œ:\n",
    "        # ì´ë¯¸ í™•ë¥ ì´ ê³„ì‚°ë˜ì–´ ìˆëŠ” ì»¬ëŸ¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "        valid_probs = model.predict(fold_valid)['ì„ì‹  ì„±ê³µ ì—¬ë¶€_1_probability'].values\n",
    "\n",
    "        # # ë§Œë“¤ì–´ ë†“ì€ 'NA' ì¹´í…Œê³ ë¦¬ë¥¼ ì œê±°í•¨\n",
    "        # fold_valid['ì„ì‹  ì„±ê³µ ì—¬ë¶€'] = fold_valid['ì„ì‹  ì„±ê³µ ì—¬ë¶€'].cat.remove_categories(['NA'])\n",
    "\n",
    "        # ì‹¤ì œ ì •ë‹µ \n",
    "        y_valid = fold_valid['ì„ì‹  ì„±ê³µ ì—¬ë¶€'].values.astype(int)\n",
    "\n",
    "\n",
    "        # í‰ê°€ ì§€í‘œ ê³„ì‚°: í´ë˜ìŠ¤ 1ì˜ í™•ë¥  ì‚¬ìš©\n",
    "        fold_auc = roc_auc_score(y_valid, valid_probs)\n",
    "        print(f\"Seed[{seed:<3}] Fold {fold + 1} | AUC: {fold_auc:.6f}\")\n",
    "        \n",
    "        auc_scores.append(fold_auc)\n",
    "        total_auc.append(fold_auc)\n",
    "\n",
    "        # Test ë°ì´í„° ì˜ˆì¸¡ (ê° foldì˜ ëª¨ë¸ë¡œ ì˜ˆì¸¡í•œ ê²°ê³¼ ì €ì¥)\n",
    "        test_pred = model.predict(fold_test)['ì„ì‹  ì„±ê³µ ì—¬ë¶€_1_probability'].values\n",
    "        test_preds.append(test_pred)\n",
    "    \n",
    "    # Fold ë³„ í‰ê·  ì„±ëŠ¥ ì¶œë ¥\n",
    "    avg_auc = np.mean(auc_scores)\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Seed[{seed:<3}] Average Metrics | AUC: {avg_auc:.7f}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# ì „ì²´ Validation í‰ê·  ì„±ëŠ¥ ì¶œë ¥\n",
    "val_auc = np.mean(total_auc)\n",
    "print(\"-\" * 80)\n",
    "print(f\"Validation Average Metrics | AUC: {val_auc:.7f}\")\n",
    "\n",
    "finish_time = time.time()\n",
    "total_time = finish_time - start_time \n",
    "\n",
    "print(total_time)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 333\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                  | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | _backbone        | FTTransformerBackbone | 68.2 K | train\n",
      "1 | _embedding_layer | Embedding2dLayer      | 2.9 K  | train\n",
      "2 | _head            | LinearHead            | 34     | train\n",
      "3 | loss             | CrossEntropyLoss      | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "71.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "71.2 K    Total params\n",
      "0.285     Total estimated model params size (MB)\n",
      "138       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bd522d960fd462897d0425ecf3bd0e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdf79b574ef34c4f9564b5bf36f541e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-30T14:49:48.718787Z",
     "start_time": "2025-03-30T14:49:48.701790Z"
    }
   },
   "source": [
    "old_auc = 0.744533 * 100\n",
    "\n",
    "new_auc = val_auc * 100\n",
    "\n",
    "def calculate_change(old_value, new_value):\n",
    "    change = new_value - old_value\n",
    "    percentage_change = (change / old_value) * 100 if old_value != 0 else float('inf')\n",
    "    return change, percentage_change\n",
    "\n",
    "def format_change(change):\n",
    "    return f\"{change:+.6f}\"\n",
    "\n",
    "# ê° ì§€í‘œì˜ ë³€í™”ëŸ‰ ê³„ì‚°\n",
    "auc_change, auc_pct = calculate_change(old_auc, new_auc)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\n======= ëª¨ë¸ ì„±ëŠ¥ ë³€í™” =======\")\n",
    "print(f\"{'Metric':<8}  {'AUC':>12}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"{'Old':<8}  {old_auc:>12.6f}\")\n",
    "print(f\"{'New':<8}  {new_auc:>12.6f}\")\n",
    "print(f\"{'Change':<8}  {format_change(auc_change):>12}\")\n",
    "print(f\"{'% Change':<8}  {auc_pct:>11.4f}%\")\n",
    "print(\"=\" * 30)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= ëª¨ë¸ ì„±ëŠ¥ ë³€í™” =======\n",
      "Metric             AUC\n",
      "------------------------------\n",
      "Old          74.453300\n",
      "New          73.588129\n",
      "Change       -0.865171\n",
      "% Change      -1.1620%\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:50:00.628296Z",
     "start_time": "2025-03-30T14:50:00.613296Z"
    }
   },
   "source": [
    "tmp_submission = pd.DataFrame({f'tabm_{data_seed}': np.mean(test_preds, axis=0)})\n",
    "tmp_submission"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         tabm_7\n",
       "0      0.343181\n",
       "1      0.194002\n",
       "2      0.341093\n",
       "3      0.000977\n",
       "4      0.000944\n",
       "...         ...\n",
       "51266  0.487230\n",
       "51267  0.430068\n",
       "51268  0.000907\n",
       "51269  0.524345\n",
       "51270  0.386706\n",
       "\n",
       "[51271 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tabm_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.343181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.194002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.341093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51266</th>\n",
       "      <td>0.487230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51267</th>\n",
       "      <td>0.430068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51268</th>\n",
       "      <td>0.000907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51269</th>\n",
       "      <td>0.524345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51270</th>\n",
       "      <td>0.386706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51271 rows Ã— 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:50:08.731742Z",
     "start_time": "2025-03-30T14:50:07.761297Z"
    }
   },
   "source": [
    "from LG_Aimers_6th.cal_auc import calculate_auc\n",
    "score = calculate_auc(tmp_submission, seed=data_seed)\n",
    "print(f'[seed {data_seed}]: {score}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[seed 7]: 0.7398620709235235\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê¸°ë³¸ test ë°ì´í„° AUC: 0.735959"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(sample_path)\n",
    "# # test_preds\n",
    "# sample_submission['probability'] = np.mean(test_preds, axis=0)\n",
    "\n",
    "# ratio = train['ì„ì‹  ì„±ê³µ ì—¬ë¶€'].value_counts(normalize=True)[1]\n",
    "# real_true_count = int(ratio * len(sample_submission))\n",
    "# print(f'testì˜ True ê°¯ìˆ˜: {real_true_count:<5} (ì¶”ì •)')\n",
    "\n",
    "# count = (sample_submission['probability'] >= 0.5).sum()\n",
    "# print(f'testì˜ True ê°¯ìˆ˜: {count:<5} (ì˜ˆì¸¡ ê²°ê³¼)')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now().strftime(\"%m%d_%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = 'Submission'\n",
    "if not os.path.exists(submission_path):\n",
    "    os.makedirs(submission_path)\n",
    "\n",
    "code_dir = 'Code'\n",
    "if not os.path.exists(code_dir):\n",
    "    os.makedirs(code_dir)\n",
    "\n",
    "\n",
    "submission_name = f\"submission_{now}.csv\"\n",
    "new_notebook_name = f\"code_{now}.ipynb\"\n",
    "\n",
    "sample_submission.to_csv(os.path.join(submission_path, submission_name), index=False)\n",
    "\n",
    "\n",
    "# í˜„ì¬ ë…¸íŠ¸ë¶ íŒŒì¼ ê²½ë¡œ ì§ì ‘ ì§€ì • (ì‹¤ì œ ë…¸íŠ¸ë¶ íŒŒì¼ëª…ìœ¼ë¡œ ìˆ˜ì •)\n",
    "current_notebook = os.path.join(os.getcwd(), \"CategoryEmbeddingModel_ì„ì‹  ì—¬ë¶€_ì€í•™ë‹˜ ì „ì²˜ë¦¬.ipynb\")\n",
    "\n",
    "new_notebook_path = os.path.join(code_dir, new_notebook_name)\n",
    "\n",
    "# ë…¸íŠ¸ë¶ íŒŒì¼ ë³µì‚¬\n",
    "shutil.copy(current_notebook, new_notebook_path)\n",
    "\n",
    "print(f\"Notebook saved in '{code_dir}' as '{new_notebook_name}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ SQLite ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •\n",
    "db_path = \"experiment_results.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ğŸ“Œ í…Œì´ë¸” ìƒì„± (ì²˜ìŒ ì‹¤í–‰ ì‹œ)\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS experiments (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    code_name TEXT,\n",
    "    experiment_desc TEXT,\n",
    "    auc REAL,\n",
    "    acc REAL,\n",
    "    f1 REAL\n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì‚½ì…\n",
    "cursor.execute('''\n",
    "INSERT INTO experiments (code_name, experiment_desc, auc, acc, f1)\n",
    "VALUES (?, ?, ?, ?, ?)\n",
    "''', (new_notebook_name, experiment_desc.strip(), new_auc, new_acc, new_f1))\n",
    "\n",
    "# ë³€ê²½ì‚¬í•­ ì €ì¥ & ì—°ê²° ì¢…ë£Œ\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(f\"Experiment '{new_notebook_name}' successfully saved in database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# SQLite ë°ì´í„° ì¡°íšŒ í•¨ìˆ˜\n",
    "def get_experiment_results(db_path=\"experiment_results.db\", num_results=10):\n",
    "    \"\"\"\n",
    "    SQLite ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¤‘ë³µëœ ì‹¤í—˜ ë°ì´í„°ë¥¼ ì œê±°í•˜ê³ , ìµœê·¼ num_resultsê°œì˜ ì‹¤í—˜ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜.\n",
    "    Returns:\n",
    "        - Pandas DataFrame: ì¤‘ë³µ ì œê±°ëœ ì‹¤í—˜ ë°ì´í„°\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    # ì¤‘ë³µ ì œê±° & ìµœì‹  ë°ì´í„° ì„ íƒí•˜ëŠ” SQL ì¿¼ë¦¬\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM experiments\n",
    "    WHERE id IN (\n",
    "        SELECT MAX(id)  -- ê°€ì¥ ìµœì‹  ë°ì´í„° ì„ íƒ\n",
    "        FROM experiments\n",
    "        GROUP BY code_name -- id ì œì™¸í•˜ê³  ì¤‘ë³µ íŒë‹¨\n",
    "    )\n",
    "    ORDER BY id DESC  -- ìµœì‹  ë°ì´í„°ë¶€í„° ì •ë ¬\n",
    "    LIMIT {num_results};\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = get_experiment_results(num_results=100)\n",
    "df_results.to_csv('experiment_results.csv', index=False, encoding='utf-8-sig', float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
