{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:27:10.305744Z",
     "start_time": "2025-04-04T08:27:10.290731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# conda install -c conda-forge faiss-gpu\n",
    "\n",
    "# conda 가상환경 상에서 설치"
   ],
   "id": "6574b27e2f56ef2c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:27:12.640981Z",
     "start_time": "2025-04-04T08:27:10.308741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 현재 작업 디렉토리(Eunhak)에서 tabular_dl_tabr 경로 추가\n",
    "project_path = os.path.join(os.getcwd(), \"tabular_dl_tabr\")\n",
    "if project_path not in sys.path:\n",
    "    sys.path.insert(0, project_path)\n",
    "\n",
    "\n",
    "project_dir = Path(r\"C:\\workspace\\LG_Aimers_6th\\Eunhak\\tabular_dl_tabr\")\n",
    "os.environ['PROJECT_DIR'] = str(project_dir)\n",
    "\n",
    "# 경로가 존재하지 않으면 생성\n",
    "if not project_dir.exists():\n",
    "    project_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import scipy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import delu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from bin.tabr import Model\n",
    "from LG_Aimers_6th.cal_auc import calculate_auc"
   ],
   "id": "a7699c4dd3ad12c9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-04T08:27:13.696350Z",
     "start_time": "2025-04-04T08:27:12.799980Z"
    }
   },
   "source": [
    "data_seed = 1\n",
    "\n",
    "train_path = f'../data/custom_train_{data_seed}.csv'\n",
    "test_path = f'../data/custom_test_{data_seed}.csv'\n",
    "\n",
    "# 학습/평가 데이터 로드\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID']) # test에는 target이 없음\n",
    "\n",
    "print(train.shape, test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205080, 68) (51271, 67)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:27:18.081503Z",
     "start_time": "2025-04-04T08:27:13.713350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from preprocess_DL import all_process\n",
    "\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "train, test = all_process(train, test)\n",
    "\n",
    "print(train.shape, test.shape)"
   ],
   "id": "d931c6a8384f4e1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205080, 66) (51271, 65)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:27:18.160503Z",
     "start_time": "2025-04-04T08:27:18.098501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_cols(df_train, target_col='임신 성공 여부'):\n",
    "    cat_cols = [col for col in df_train.columns if pd.api.types.is_categorical_dtype(df_train[col])]\n",
    "    numeric_cols = [col for col in df_train.columns if col not in cat_cols and col != '임신 성공 여부']\n",
    "\n",
    "    num_cols = []\n",
    "    bin_cols = []\n",
    "    for col in numeric_cols:\n",
    "        if df_train[col].nunique() == 2:\n",
    "            bin_cols.append(col)\n",
    "        else:\n",
    "            num_cols.append(col)\n",
    "\n",
    "    return num_cols, bin_cols, cat_cols\n",
    "\n",
    "num_cols, bin_cols, cat_cols = get_cols(train)\n",
    "cat_cardinalities = [train[col].nunique() for col in cat_cols]\n",
    "\n",
    "print(f'수치형 변수: {len(num_cols)}개 \\n{num_cols}')\n",
    "print(f'이진형 변수: {len(bin_cols)}개 \\n{bin_cols}')\n",
    "print(f'범주형 변수: {len(cat_cols)}개 \\n{cat_cols}')"
   ],
   "id": "9dbb80b9a10a8558",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수치형 변수: 32개 \n",
      "['임신 시도 또는 마지막 임신 경과 연수', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', 'IVF 임신 횟수', 'DI 임신 횟수', '총 출산 횟수', 'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '이식된 배아 수', '미세주입 배아 이식 수', '저장된 배아 수', '미세주입 후 저장된 배아 수', '해동된 배아 수', '해동 난자 수', '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수', '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '난자 혼합 경과일', '배아 이식 경과일', '배아 해동 경과일', '시술_임신', '배아생성이유_기증용', '배아생성이유_난자 저장용', '배아생성이유_배아 저장용', '배아생성이유_현재 시술용']\n",
      "이진형 변수: 25개 \n",
      "['배란 자극 여부', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인', '불명확 불임 원인', '불임 원인 - 난관 질환', '불임 원인 - 남성 요인', '불임 원인 - 배란 장애', '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증', '불임 원인 - 정자 농도', '불임 원인 - 정자 운동성', '불임 원인 - 정자 형태', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '대리모 여부', 'PGD 시술 여부', 'PGS 시술 여부']\n",
      "범주형 변수: 8개 \n",
      "['시술 시기 코드', '시술 당시 나이', '배란 유도 유형', '난자 출처', '정자 출처', '난자 기증자 나이', '정자 기증자 나이', '시술유형_통합']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:27:18.191500Z",
     "start_time": "2025-04-04T08:27:18.176501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_dataset_from_dfs(train_df, valid_df, test_df, num_cols, bin_cols, cat_cols, target_col='임신 성공 여부'):\n",
    "    data = {}\n",
    "    data['X_num'] = {\n",
    "        'train': torch.tensor(train_df[num_cols].values, dtype=torch.float32),\n",
    "        'val':   torch.tensor(valid_df[num_cols].values, dtype=torch.float32),\n",
    "        'test':  torch.tensor(test_df[num_cols].values, dtype=torch.float32),\n",
    "    }\n",
    "    data['X_bin'] = {\n",
    "        'train': torch.tensor(train_df[bin_cols].values, dtype=torch.float32),\n",
    "        'val':   torch.tensor(valid_df[bin_cols].values, dtype=torch.float32),\n",
    "        'test':  torch.tensor(test_df[bin_cols].values, dtype=torch.float32),\n",
    "    }\n",
    "    if cat_cols:\n",
    "        data['X_cat'] = {\n",
    "            'train': torch.tensor(train_df[cat_cols].values, dtype=torch.long),\n",
    "            'val':   torch.tensor(valid_df[cat_cols].values, dtype=torch.long),\n",
    "            'test':  torch.tensor(test_df[cat_cols].values, dtype=torch.long),\n",
    "        }\n",
    "    else:\n",
    "        data['X_cat'] = None\n",
    "    data['Y'] = {\n",
    "        'train': torch.tensor(train_df[target_col].values, dtype=torch.long),\n",
    "        'val':   torch.tensor(valid_df[target_col].values, dtype=torch.long),\n",
    "        # test 데이터에는 타깃이 없을 수 있습니다.\n",
    "    }\n",
    "    return data\n",
    "\n",
    "def move_data_to_device(data, device):\n",
    "    # data는 dict 형식: 예) {'X_num': {'train': tensor, 'val': tensor, ...}, ...}\n",
    "    for key in data:\n",
    "        if data[key] is None:\n",
    "            continue\n",
    "        if isinstance(data[key], dict):\n",
    "            for part in data[key]:\n",
    "                data[key][part] = data[key][part].to(device)\n",
    "        else:\n",
    "            data[key] = data[key].to(device)\n",
    "    return data\n",
    "\n",
    "\n",
    "class MyDataset:\n",
    "    def __init__(self, data, n_num_features, n_bin_features, cat_cardinalities, is_regression=False, is_multiclass=True):\n",
    "        self.data = data\n",
    "        self._n_num_features = n_num_features\n",
    "        self._n_bin_features = n_bin_features\n",
    "        self._cat_cardinalities = cat_cardinalities\n",
    "        self.is_regression = is_regression\n",
    "        self.is_multiclass = is_multiclass\n",
    "\n",
    "    @property\n",
    "    def n_num_features(self):\n",
    "        return self._n_num_features\n",
    "\n",
    "    @property\n",
    "    def n_bin_features(self):\n",
    "        return self._n_bin_features\n",
    "\n",
    "    def cat_cardinalities(self):\n",
    "        return self._cat_cardinalities\n",
    "\n",
    "    @property\n",
    "    def Y(self):\n",
    "        return self.data['Y']\n",
    "\n",
    "    def size(self, part: str) -> int:\n",
    "        # target이 있는 경우 사용\n",
    "        if part in self.data['Y']:\n",
    "            return self.data['Y'][part].shape[0]\n",
    "        else:\n",
    "            return self.data['X_num'][part].shape[0]\n",
    "\n",
    "# data_dict = build_dataset_from_dfs(train, valid, test, num_cols, bin_cols, cat_cols, target_col='임신 성공 여부')\n",
    "# data_dict = move_data_to_device(data_dict, device)\n",
    "#\n",
    "# dataset = MyDataset(data_dict, n_num_features=len(num_cols), n_bin_features=len(bin_cols), cat_cardinalities=cat_cardinalities)"
   ],
   "id": "cf40ff609df1c64b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:27:18.223500Z",
     "start_time": "2025-04-04T08:27:18.208502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_Xy(part: str, idx: torch.Tensor = None) -> tuple[dict, torch.Tensor]:\n",
    "    batch = (\n",
    "        { key[2:]: dataset.data[key][part] for key in dataset.data if key.startswith('X_') },\n",
    "        dataset.data['Y'][part] if 'Y' in dataset.data and part in dataset.data['Y'] else None\n",
    "    )\n",
    "    if idx is None:\n",
    "        return batch\n",
    "    else:\n",
    "        return (\n",
    "            {k: v[idx] for k, v in batch[0].items()},\n",
    "            batch[1][idx] if batch[1] is not None else None\n",
    "        )\n",
    "\n",
    "# train_size = dataset.size('train')\n",
    "# train_indices = torch.arange(train_size, device=device)"
   ],
   "id": "691e8030d5feac88",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:27:19.080491Z",
     "start_time": "2025-04-04T08:27:18.240502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Model(\n",
    "    n_num_features=len(num_cols),\n",
    "    n_bin_features=len(bin_cols),\n",
    "    cat_cardinalities=cat_cardinalities,\n",
    "    n_classes=2,\n",
    "    num_embeddings=None,      # 임베딩 사용하지 않을 경우 None\n",
    "    d_main=64,\n",
    "    d_multiplier=2.0,\n",
    "    encoder_n_blocks=2,\n",
    "    predictor_n_blocks=2,\n",
    "    mixer_normalization=True,\n",
    "    context_dropout=0.1,\n",
    "    dropout0=0.1,\n",
    "    dropout1='dropout0',      # 'dropout0' 문자열을 지정하면 내부에서 dropout0 값이 사용됩니다.\n",
    "    normalization=\"BatchNorm1d\",\n",
    "    activation=\"ReLU\",\n",
    "    memory_efficient=False,\n",
    "    candidate_encoding_batch_size=None,\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ],
   "id": "d52517b7938dcaf7",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:27:19.112488Z",
     "start_time": "2025-04-04T08:27:19.097489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_model(part: str, idx: torch.Tensor, is_train: bool) -> torch.Tensor:\n",
    "    x, y = get_Xy(part, idx)\n",
    "    candidate_indices = train_indices\n",
    "    if is_train:\n",
    "        # training part: 후보에서 현재 배치 제거\n",
    "        candidate_indices = candidate_indices[~torch.isin(candidate_indices, idx)]\n",
    "    # 후보 데이터: 조건에 따라 전체 train 또는 선택된 인덱스 사용\n",
    "    candidate_x, candidate_y = get_Xy('train', None if candidate_indices.equal(train_indices) else candidate_indices)\n",
    "    return model(\n",
    "        x_=x,\n",
    "        y=y if is_train else None,\n",
    "        candidate_x_=candidate_x,\n",
    "        candidate_y=candidate_y,\n",
    "        context_size=5,\n",
    "        is_train=is_train,\n",
    "    ).squeeze(-1)\n"
   ],
   "id": "582b27aec832b9a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:32:16.677646Z",
     "start_time": "2025-04-04T08:27:19.129489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed = 333\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "delu.random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "test_preds = []\n",
    "val_scores = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train['임신 성공 여부'])):\n",
    "    fold_train = train.iloc[train_idx].copy().reset_index(drop=True)\n",
    "    fold_valid = train.iloc[valid_idx].copy().reset_index(drop=True)\n",
    "    fold_train2 = fold_train.copy()\n",
    "    fold_test = test.copy()\n",
    "\n",
    "    fold_train, fold_valid = all_process(fold_train, fold_valid)\n",
    "    _, fold_test = all_process(fold_train2, fold_test)\n",
    "\n",
    "    num_cols, bin_cols, cat_cols = get_cols(fold_train)\n",
    "    cat_cardinalities = [fold_train[col].nunique() for col in cat_cols]\n",
    "\n",
    "    data_dict = build_dataset_from_dfs(\n",
    "        fold_train, fold_valid, fold_test,\n",
    "        num_cols, bin_cols, cat_cols, target_col='임신 성공 여부'\n",
    "    )\n",
    "    data_dict = move_data_to_device(data_dict, device)\n",
    "    dataset = MyDataset(data_dict, n_num_features=len(num_cols), n_bin_features=len(bin_cols), cat_cardinalities=cat_cardinalities)\n",
    "\n",
    "    train_size = dataset.size('train')\n",
    "    train_indices = torch.arange(train_size, device=device)\n",
    "\n",
    "    model = Model(\n",
    "        n_num_features=len(num_cols),\n",
    "        n_bin_features=len(bin_cols),\n",
    "        cat_cardinalities=cat_cardinalities,\n",
    "        n_classes=2,\n",
    "        num_embeddings=None,      # 임베딩 사용하지 않을 경우 None\n",
    "        d_main=64,\n",
    "        d_multiplier=2.0,\n",
    "        encoder_n_blocks=2,\n",
    "        predictor_n_blocks=2,\n",
    "        mixer_normalization=True,\n",
    "        context_dropout=0.1,\n",
    "        dropout0=0.1,\n",
    "        dropout1='dropout0',      # 'dropout0' 문자열을 지정하면 내부에서 dropout0 값이 사용됩니다.\n",
    "        normalization=\"BatchNorm1d\",\n",
    "        activation=\"ReLU\",\n",
    "        memory_efficient=False,\n",
    "        candidate_encoding_batch_size=None,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    num_epochs = 100000\n",
    "    batch_size = 2048\n",
    "\n",
    "    patience = 10\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    checkpoint_path = \"best_model_TabR.pth\"\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        # 학습 데이터 인덱스 섞기\n",
    "        shuffled_indices = train_indices[torch.randperm(train_size)]\n",
    "        num_batches = math.ceil(train_size / batch_size)\n",
    "        epoch_loss = 0.0\n",
    "        for i in range(num_batches):\n",
    "            idx = shuffled_indices[i * batch_size : (i + 1) * batch_size]\n",
    "            outputs = apply_model('train', idx, is_train=True)\n",
    "\n",
    "            # 해당 인덱스의 타깃\n",
    "            _, y_batch = get_Xy('train', idx)\n",
    "\n",
    "            y_batch = y_batch.float()\n",
    "            loss = criterion(outputs.squeeze(), y_batch.squeeze()) # squeeze해서 shape 맞추기 (예: (batch_size,))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * idx.numel()\n",
    "\n",
    "        avg_loss = epoch_loss / train_size\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_indices = torch.arange(dataset.size('val'), device=device)\n",
    "            outputs_val = apply_model('val', val_indices, is_train=False)\n",
    "            _, y_val = get_Xy('val', val_indices)\n",
    "\n",
    "            val_loss = criterion(outputs_val.squeeze(), y_val.float().squeeze()).item() # validation loss 계산\n",
    "\n",
    "            outputs_val = torch.sigmoid(outputs_val)\n",
    "            outputs_val_np = outputs_val.detach().cpu().numpy().squeeze()\n",
    "            y_val_np = y_val.detach().cpu().numpy().squeeze()\n",
    "\n",
    "            val_auc = roc_auc_score(y_val_np, outputs_val_np)\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Train Loss: {avg_loss:.4f}, Valid Loss: {val_loss:.4f}, \"\n",
    "              f\"Valid AUC: {val_auc:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stop_counter = 0\n",
    "            best = {'epoch': epoch+1, 'val_loss': val_loss, 'val_auc': val_auc}\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            # print(f\"No improvement in validation loss for {early_stop_counter} epochs.\")\n",
    "            if early_stop_counter >= patience:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f'\\n\\n[Fold{fold+1} Result]')\n",
    "    print(best)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_indices = torch.arange(dataset.size('test'), device=device)\n",
    "        test_pred = apply_model('test', test_indices, is_train=False)\n",
    "        test_pred = torch.sigmoid(test_pred)\n",
    "        test_pred_np = test_pred.detach().cpu().numpy().squeeze()\n",
    "\n",
    "        test_auc = calculate_auc(test_pred_np, seed=data_seed)\n",
    "        print(f'[Data Seed {data_seed} Fold {fold+1}] Test AUC: {test_auc}')\n",
    "        test_preds.append(test_pred_np)\n",
    "\n",
    "\n",
    "final_score = calculate_auc(np.mean(test_preds, axis=0), seed=data_seed)\n",
    "print(f'[Data Seed {data_seed}] Final Test AUC: {final_score}')"
   ],
   "id": "7a2e4dcbc4842d7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.5361, Valid Loss: 0.4949, Valid AUC: 0.734636\n",
      "[Epoch 2] Train Loss: 0.4942, Valid Loss: 0.4909, Valid AUC: 0.736777\n",
      "[Epoch 3] Train Loss: 0.4919, Valid Loss: 0.4903, Valid AUC: 0.736764\n",
      "[Epoch 4] Train Loss: 0.4907, Valid Loss: 0.4887, Valid AUC: 0.738582\n",
      "[Epoch 5] Train Loss: 0.4898, Valid Loss: 0.4896, Valid AUC: 0.737865\n",
      "[Epoch 6] Train Loss: 0.4889, Valid Loss: 0.4888, Valid AUC: 0.738270\n",
      "[Epoch 7] Train Loss: 0.4885, Valid Loss: 0.4885, Valid AUC: 0.738357\n",
      "[Epoch 8] Train Loss: 0.4879, Valid Loss: 0.4888, Valid AUC: 0.739338\n",
      "[Epoch 9] Train Loss: 0.4876, Valid Loss: 0.4885, Valid AUC: 0.738541\n",
      "[Epoch 10] Train Loss: 0.4870, Valid Loss: 0.4883, Valid AUC: 0.738504\n",
      "[Epoch 11] Train Loss: 0.4869, Valid Loss: 0.4881, Valid AUC: 0.739098\n",
      "[Epoch 12] Train Loss: 0.4862, Valid Loss: 0.4881, Valid AUC: 0.738658\n",
      "[Epoch 13] Train Loss: 0.4861, Valid Loss: 0.4877, Valid AUC: 0.739704\n",
      "[Epoch 14] Train Loss: 0.4853, Valid Loss: 0.4885, Valid AUC: 0.738698\n",
      "[Epoch 15] Train Loss: 0.4851, Valid Loss: 0.4887, Valid AUC: 0.737943\n",
      "[Epoch 16] Train Loss: 0.4844, Valid Loss: 0.4884, Valid AUC: 0.738545\n",
      "[Epoch 17] Train Loss: 0.4845, Valid Loss: 0.4894, Valid AUC: 0.737998\n",
      "[Epoch 18] Train Loss: 0.4840, Valid Loss: 0.4888, Valid AUC: 0.738032\n",
      "[Epoch 19] Train Loss: 0.4837, Valid Loss: 0.4882, Valid AUC: 0.738712\n",
      "[Epoch 20] Train Loss: 0.4835, Valid Loss: 0.4883, Valid AUC: 0.738736\n",
      "[Epoch 21] Train Loss: 0.4833, Valid Loss: 0.4888, Valid AUC: 0.737739\n",
      "[Epoch 22] Train Loss: 0.4831, Valid Loss: 0.4891, Valid AUC: 0.738141\n",
      "[Epoch 23] Train Loss: 0.4823, Valid Loss: 0.4893, Valid AUC: 0.737482\n",
      "\n",
      "\n",
      "[Fold1 Result]\n",
      "{'epoch': 13, 'val_loss': 0.4876715838909149, 'val_auc': 0.7397038959909201}\n",
      "[Data Seed 1 Fold 1] Test AUC: 0.7372883769359918\n",
      "[Epoch 1] Train Loss: 0.5369, Valid Loss: 0.4960, Valid AUC: 0.731376\n",
      "[Epoch 2] Train Loss: 0.4942, Valid Loss: 0.4925, Valid AUC: 0.733258\n",
      "[Epoch 3] Train Loss: 0.4916, Valid Loss: 0.4923, Valid AUC: 0.734703\n",
      "[Epoch 4] Train Loss: 0.4901, Valid Loss: 0.4908, Valid AUC: 0.735441\n",
      "[Epoch 5] Train Loss: 0.4889, Valid Loss: 0.4913, Valid AUC: 0.735180\n",
      "[Epoch 6] Train Loss: 0.4885, Valid Loss: 0.4902, Valid AUC: 0.735927\n",
      "[Epoch 7] Train Loss: 0.4877, Valid Loss: 0.4905, Valid AUC: 0.735368\n",
      "[Epoch 8] Train Loss: 0.4871, Valid Loss: 0.4918, Valid AUC: 0.735185\n",
      "[Epoch 9] Train Loss: 0.4870, Valid Loss: 0.4897, Valid AUC: 0.735879\n",
      "[Epoch 10] Train Loss: 0.4867, Valid Loss: 0.4906, Valid AUC: 0.735090\n",
      "[Epoch 11] Train Loss: 0.4861, Valid Loss: 0.4908, Valid AUC: 0.734707\n",
      "[Epoch 12] Train Loss: 0.4860, Valid Loss: 0.4904, Valid AUC: 0.735253\n",
      "[Epoch 13] Train Loss: 0.4855, Valid Loss: 0.4905, Valid AUC: 0.735174\n",
      "[Epoch 14] Train Loss: 0.4850, Valid Loss: 0.4908, Valid AUC: 0.734755\n",
      "[Epoch 15] Train Loss: 0.4848, Valid Loss: 0.4906, Valid AUC: 0.734740\n",
      "[Epoch 16] Train Loss: 0.4845, Valid Loss: 0.4906, Valid AUC: 0.735004\n",
      "[Epoch 17] Train Loss: 0.4840, Valid Loss: 0.4907, Valid AUC: 0.735547\n",
      "[Epoch 18] Train Loss: 0.4835, Valid Loss: 0.4904, Valid AUC: 0.735181\n",
      "[Epoch 19] Train Loss: 0.4832, Valid Loss: 0.4912, Valid AUC: 0.734003\n",
      "\n",
      "\n",
      "[Fold2 Result]\n",
      "{'epoch': 9, 'val_loss': 0.4897157549858093, 'val_auc': 0.7358793845394377}\n",
      "[Data Seed 1 Fold 2] Test AUC: 0.7378665634660477\n",
      "[Epoch 1] Train Loss: 0.5242, Valid Loss: 0.4955, Valid AUC: 0.731246\n",
      "[Epoch 2] Train Loss: 0.4943, Valid Loss: 0.4920, Valid AUC: 0.734962\n",
      "[Epoch 3] Train Loss: 0.4916, Valid Loss: 0.4912, Valid AUC: 0.735452\n",
      "[Epoch 4] Train Loss: 0.4903, Valid Loss: 0.4907, Valid AUC: 0.736184\n",
      "[Epoch 5] Train Loss: 0.4893, Valid Loss: 0.4901, Valid AUC: 0.736900\n",
      "[Epoch 6] Train Loss: 0.4888, Valid Loss: 0.4895, Valid AUC: 0.737782\n",
      "[Epoch 7] Train Loss: 0.4881, Valid Loss: 0.4902, Valid AUC: 0.737493\n",
      "[Epoch 8] Train Loss: 0.4875, Valid Loss: 0.4896, Valid AUC: 0.737600\n",
      "[Epoch 9] Train Loss: 0.4870, Valid Loss: 0.4901, Valid AUC: 0.738708\n",
      "[Epoch 10] Train Loss: 0.4868, Valid Loss: 0.4897, Valid AUC: 0.738547\n",
      "[Epoch 11] Train Loss: 0.4865, Valid Loss: 0.4891, Valid AUC: 0.738781\n",
      "[Epoch 12] Train Loss: 0.4859, Valid Loss: 0.4895, Valid AUC: 0.738474\n",
      "[Epoch 13] Train Loss: 0.4854, Valid Loss: 0.4898, Valid AUC: 0.737990\n",
      "[Epoch 14] Train Loss: 0.4853, Valid Loss: 0.4900, Valid AUC: 0.737721\n",
      "[Epoch 15] Train Loss: 0.4850, Valid Loss: 0.4897, Valid AUC: 0.737909\n",
      "[Epoch 16] Train Loss: 0.4847, Valid Loss: 0.4899, Valid AUC: 0.737452\n",
      "[Epoch 17] Train Loss: 0.4843, Valid Loss: 0.4907, Valid AUC: 0.736974\n",
      "[Epoch 18] Train Loss: 0.4841, Valid Loss: 0.4906, Valid AUC: 0.736412\n",
      "[Epoch 19] Train Loss: 0.4836, Valid Loss: 0.4904, Valid AUC: 0.737615\n",
      "[Epoch 20] Train Loss: 0.4833, Valid Loss: 0.4905, Valid AUC: 0.737127\n",
      "[Epoch 21] Train Loss: 0.4826, Valid Loss: 0.4899, Valid AUC: 0.737351\n",
      "\n",
      "\n",
      "[Fold3 Result]\n",
      "{'epoch': 11, 'val_loss': 0.4890771508216858, 'val_auc': 0.7387809452737799}\n",
      "[Data Seed 1 Fold 3] Test AUC: 0.7378252365618072\n",
      "[Epoch 1] Train Loss: 0.5483, Valid Loss: 0.4977, Valid AUC: 0.728680\n",
      "[Epoch 2] Train Loss: 0.4945, Valid Loss: 0.4927, Valid AUC: 0.732983\n",
      "[Epoch 3] Train Loss: 0.4917, Valid Loss: 0.4929, Valid AUC: 0.731368\n",
      "[Epoch 4] Train Loss: 0.4904, Valid Loss: 0.4918, Valid AUC: 0.733158\n",
      "[Epoch 5] Train Loss: 0.4898, Valid Loss: 0.4912, Valid AUC: 0.733976\n",
      "[Epoch 6] Train Loss: 0.4887, Valid Loss: 0.4907, Valid AUC: 0.734492\n",
      "[Epoch 7] Train Loss: 0.4879, Valid Loss: 0.4904, Valid AUC: 0.735278\n",
      "[Epoch 8] Train Loss: 0.4873, Valid Loss: 0.4902, Valid AUC: 0.736200\n",
      "[Epoch 9] Train Loss: 0.4873, Valid Loss: 0.4899, Valid AUC: 0.736202\n",
      "[Epoch 10] Train Loss: 0.4868, Valid Loss: 0.4897, Valid AUC: 0.736317\n",
      "[Epoch 11] Train Loss: 0.4863, Valid Loss: 0.4897, Valid AUC: 0.736189\n",
      "[Epoch 12] Train Loss: 0.4857, Valid Loss: 0.4898, Valid AUC: 0.736179\n",
      "[Epoch 13] Train Loss: 0.4856, Valid Loss: 0.4900, Valid AUC: 0.735281\n",
      "[Epoch 14] Train Loss: 0.4852, Valid Loss: 0.4911, Valid AUC: 0.734150\n",
      "[Epoch 15] Train Loss: 0.4846, Valid Loss: 0.4903, Valid AUC: 0.735460\n",
      "[Epoch 16] Train Loss: 0.4848, Valid Loss: 0.4904, Valid AUC: 0.734621\n",
      "[Epoch 17] Train Loss: 0.4841, Valid Loss: 0.4901, Valid AUC: 0.735488\n",
      "[Epoch 18] Train Loss: 0.4839, Valid Loss: 0.4905, Valid AUC: 0.735008\n",
      "[Epoch 19] Train Loss: 0.4835, Valid Loss: 0.4900, Valid AUC: 0.736232\n",
      "[Epoch 20] Train Loss: 0.4835, Valid Loss: 0.4911, Valid AUC: 0.735182\n",
      "[Epoch 21] Train Loss: 0.4828, Valid Loss: 0.4910, Valid AUC: 0.735113\n",
      "\n",
      "\n",
      "[Fold4 Result]\n",
      "{'epoch': 11, 'val_loss': 0.4896990656852722, 'val_auc': 0.7361892003255603}\n",
      "[Data Seed 1 Fold 4] Test AUC: 0.7382875735475649\n",
      "[Epoch 1] Train Loss: 0.5429, Valid Loss: 0.4943, Valid AUC: 0.732519\n",
      "[Epoch 2] Train Loss: 0.4948, Valid Loss: 0.4927, Valid AUC: 0.734238\n",
      "[Epoch 3] Train Loss: 0.4918, Valid Loss: 0.4918, Valid AUC: 0.733607\n",
      "[Epoch 4] Train Loss: 0.4905, Valid Loss: 0.4911, Valid AUC: 0.733206\n",
      "[Epoch 5] Train Loss: 0.4895, Valid Loss: 0.4901, Valid AUC: 0.735204\n",
      "[Epoch 6] Train Loss: 0.4887, Valid Loss: 0.4892, Valid AUC: 0.737162\n",
      "[Epoch 7] Train Loss: 0.4882, Valid Loss: 0.4906, Valid AUC: 0.734507\n",
      "[Epoch 8] Train Loss: 0.4873, Valid Loss: 0.4903, Valid AUC: 0.735874\n",
      "[Epoch 9] Train Loss: 0.4872, Valid Loss: 0.4900, Valid AUC: 0.735214\n",
      "[Epoch 10] Train Loss: 0.4865, Valid Loss: 0.4896, Valid AUC: 0.735902\n",
      "[Epoch 11] Train Loss: 0.4861, Valid Loss: 0.4894, Valid AUC: 0.736805\n",
      "[Epoch 12] Train Loss: 0.4858, Valid Loss: 0.4899, Valid AUC: 0.736093\n",
      "[Epoch 13] Train Loss: 0.4856, Valid Loss: 0.4902, Valid AUC: 0.735380\n",
      "[Epoch 14] Train Loss: 0.4855, Valid Loss: 0.4892, Valid AUC: 0.736949\n",
      "[Epoch 15] Train Loss: 0.4847, Valid Loss: 0.4900, Valid AUC: 0.737011\n",
      "[Epoch 16] Train Loss: 0.4846, Valid Loss: 0.4898, Valid AUC: 0.736251\n",
      "[Epoch 17] Train Loss: 0.4841, Valid Loss: 0.4897, Valid AUC: 0.736893\n",
      "[Epoch 18] Train Loss: 0.4840, Valid Loss: 0.4901, Valid AUC: 0.736262\n",
      "[Epoch 19] Train Loss: 0.4835, Valid Loss: 0.4896, Valid AUC: 0.736424\n",
      "[Epoch 20] Train Loss: 0.4827, Valid Loss: 0.4896, Valid AUC: 0.736844\n",
      "[Epoch 21] Train Loss: 0.4827, Valid Loss: 0.4900, Valid AUC: 0.736427\n",
      "[Epoch 22] Train Loss: 0.4822, Valid Loss: 0.4908, Valid AUC: 0.735343\n",
      "[Epoch 23] Train Loss: 0.4822, Valid Loss: 0.4915, Valid AUC: 0.733986\n",
      "[Epoch 24] Train Loss: 0.4819, Valid Loss: 0.4910, Valid AUC: 0.734161\n",
      "\n",
      "\n",
      "[Fold5 Result]\n",
      "{'epoch': 14, 'val_loss': 0.4891855716705322, 'val_auc': 0.7369493597525719}\n",
      "[Data Seed 1 Fold 5] Test AUC: 0.7356922209307255\n",
      "[Data Seed 1] Final Test AUC: 0.7395654892603754\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:32:16.866905Z",
     "start_time": "2025-04-04T08:32:16.851903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "submission = pd.DataFrame({f'tabr_{data_seed}': np.mean(test_preds, axis=0)})\n",
    "submission"
   ],
   "id": "29e90998823c991c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         tabr_1\n",
       "0      0.200010\n",
       "1      0.190900\n",
       "2      0.001739\n",
       "3      0.188189\n",
       "4      0.385195\n",
       "...         ...\n",
       "51266  0.000562\n",
       "51267  0.313677\n",
       "51268  0.103488\n",
       "51269  0.000334\n",
       "51270  0.001509\n",
       "\n",
       "[51271 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tabr_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.190900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.188189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.385195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51266</th>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51267</th>\n",
       "      <td>0.313677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51268</th>\n",
       "      <td>0.103488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51269</th>\n",
       "      <td>0.000334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51270</th>\n",
       "      <td>0.001509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51271 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:32:16.945903Z",
     "start_time": "2025-04-04T08:32:16.898905Z"
    }
   },
   "cell_type": "code",
   "source": "submission.to_csv(f'TabR_{data_seed}.csv', index=False)",
   "id": "9ff3a0f8308818f3",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:32:16.993905Z",
     "start_time": "2025-04-04T08:32:16.978904Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5a8014e0753892d0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
