{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T10:55:34.701110Z",
     "start_time": "2025-04-05T10:55:34.034948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def f1_score(true_prob, pred_prob):\n",
    "    true_binary = (np.array(true_prob) > 0.5).astype(int)\n",
    "    pred_binary = (np.array(pred_prob) > 0.5).astype(int)\n",
    "    return metrics.f1_score(true_binary, pred_binary)\n",
    "\n",
    "def weighted_brier_score(true_prob, pred_prob, alpha=4):\n",
    "    weights = 1 + alpha * true_prob + np.abs(0.5 - true_prob) ** 2\n",
    "    brier = np.sum(weights * (true_prob - pred_prob) ** 2) / np.sum(weights)\n",
    "    adjusted_brier = max(0, 1 - brier)\n",
    "    return adjusted_brier\n",
    "\n",
    "def competition_metric(true_prob, pred_prob):\n",
    "    true_prob = np.array(true_prob)\n",
    "    pred_prob = np.array(pred_prob)\n",
    "\n",
    "    if true_prob.shape != pred_prob.shape:\n",
    "        raise ValueError(\"예측값과 정답값의 shape이 일치하지 않습니다.\")\n",
    "    if np.isnan(pred_prob).any():\n",
    "        raise ValueError(\"예측값에 NaN이 포함되어 있습니다.\")\n",
    "    if not ((0 <= pred_prob) & (pred_prob <= 1)).all():\n",
    "        raise ValueError(\"예측값이 0~1 범위를 벗어났습니다.\")\n",
    "    if not np.isfinite(pred_prob).all():\n",
    "        raise ValueError(\"예측값에 inf 또는 -inf가 포함되어 있습니다.\")\n",
    "\n",
    "    wbs = weighted_brier_score(true_prob, pred_prob)\n",
    "    f1 = f1_score(true_prob, pred_prob)\n",
    "    score = 0.5 * wbs + 0.5 * f1\n",
    "    return score"
   ],
   "id": "f8fd97701ce44125",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T10:55:34.717113Z",
     "start_time": "2025-04-05T10:55:34.704116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# conda install -c conda-forge faiss-gpu\n",
    "\n",
    "# conda 가상환경 상에서 설치"
   ],
   "id": "6574b27e2f56ef2c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T10:55:36.357534Z",
     "start_time": "2025-04-05T10:55:34.844183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 현재 작업 디렉토리(Eunhak)에서 tabular_dl_tabr 경로 추가\n",
    "project_path = os.path.join(os.getcwd(), \"tabular_dl_tabr\")\n",
    "if project_path not in sys.path:\n",
    "    sys.path.insert(0, project_path)\n",
    "\n",
    "\n",
    "project_dir = Path(r\"C:\\workspace\\LG_Aimers_6th\\Eunhak\\tabular_dl_tabr\")\n",
    "os.environ['PROJECT_DIR'] = str(project_dir)\n",
    "\n",
    "# 경로가 존재하지 않으면 생성\n",
    "if not project_dir.exists():\n",
    "    project_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import scipy\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import delu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from bin.tabr import Model\n",
    "from LG_Aimers_6th.cal_auc import calculate_auc"
   ],
   "id": "a7699c4dd3ad12c9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-05T10:55:36.801683Z",
     "start_time": "2025-04-05T10:55:36.374536Z"
    }
   },
   "source": [
    "train_path = '../offline_data/train_aimers_6th_offline.csv'\n",
    "test_path = '../offline_data/test_aimers_6th_offline.csv'\n",
    "sample_path = '../offline_data/sample_submission_aimers_6th_offline.csv'\n",
    "\n",
    "train = pd.read_csv(train_path, encoding='utf-8-sig').drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path, encoding='utf-8-sig').drop(columns=['ID'])\n",
    "\n",
    "task_type = 'regression'\n",
    "\n",
    "print(train.shape, test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126244, 34) (54412, 33)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T10:55:36.896682Z",
     "start_time": "2025-04-05T10:55:36.818684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, QuantileTransformer, MultiLabelBinarizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "def drop_cols_with_na(train_df, val_df):\n",
    "    # 나중에 결측치 대체하면서 반영할 예정\n",
    "\n",
    "    cat_cols_with_na = [\n",
    "        '이전 총 임신 횟수',\n",
    "        '이전 총 임신 성공 횟수',\n",
    "\n",
    "        '총 생성 배아 수', ## 여기부터 100% DI\n",
    "        '저장된 배아 수',\n",
    "        '채취된 신선 난자 수',\n",
    "        '수정 시도된 난자 수'\n",
    "    ]\n",
    "\n",
    "    numeric_cols_with_na = [\n",
    "        '이식된 배아 수', ## only DI\n",
    "        '미세주입(ICSI) 배아 이식 수',\n",
    "        '배아 이식 후 경과일',\n",
    "    ]\n",
    "    train_df = train_df.drop(columns=cat_cols_with_na)\n",
    "    train_df = train_df.drop(columns=numeric_cols_with_na)\n",
    "    val_df = val_df.drop(columns=cat_cols_with_na)\n",
    "    val_df = val_df.drop(columns=numeric_cols_with_na)\n",
    "    return train_df, val_df\n",
    "\n",
    "\n",
    "def 시술유형(train, test):\n",
    "    train['세부 시술 유형'] = train['세부 시술 유형'].fillna(\"Unknown\")\n",
    "    test['세부 시술 유형'] = test['세부 시술 유형'].fillna(\"Unknown\")\n",
    "\n",
    "    def categorize_procedure(proc):\n",
    "        tokens = [token.strip() for token in proc.split(\",\") if token.strip() and not token.strip().isdigit()]\n",
    "        # 우선순위에 따른 범주화\n",
    "        if tokens.count(\"Unknown\") >= 1:\n",
    "            return \"Unknown\"\n",
    "        if tokens.count(\"AH\") >= 1:\n",
    "            return \"AH\"\n",
    "        if tokens.count(\"BLASTOCYST\") >= 1:\n",
    "            return \"BLASTOCYST\"\n",
    "        if tokens.count(\"ICSI\") >= 2 or tokens.count(\"IVF\") >= 2:\n",
    "            return \"2ICSI_2IVF\"\n",
    "        if tokens.count(\"IVF\") >= 1 and tokens.count(\"ICSI\") >= 1:\n",
    "            return \"IVF_ICSI\"\n",
    "        if tokens == \"ICSI\":\n",
    "            return \"ICSI\"\n",
    "        if tokens == \"IVF\":\n",
    "            return \"IVF\"\n",
    "        return \",\".join(tokens) if tokens else None\n",
    "\n",
    "    for df in [train, test]:\n",
    "        df['세부 시술 유형'] = df['세부 시술 유형'].str.replace(\" / \", \",\")\n",
    "        df['세부 시술 유형'] = df['세부 시술 유형'].str.replace(\":\", \",\")\n",
    "        df['세부 시술 유형'] = df['세부 시술 유형'].str.replace(\" \", \"\")\n",
    "\n",
    "    counts = train['세부 시술 유형'].value_counts()\n",
    "    allowed_categories = counts[counts >= 100].index.tolist()\n",
    "\n",
    "    # allowed_categories에 속하지 않는 값은 \"Unknown\"으로 대체\n",
    "    train.loc[~train['세부 시술 유형'].isin(allowed_categories), '세부 시술 유형'] = \"Unknown\"\n",
    "    test.loc[~test['세부 시술 유형'].isin(allowed_categories), '세부 시술 유형'] = \"Unknown\"\n",
    "\n",
    "    train['세부 시술 유형'] = train['세부 시술 유형'].apply(categorize_procedure)\n",
    "    test['세부 시술 유형'] = test['세부 시술 유형'].apply(categorize_procedure)\n",
    "\n",
    "    train['시술유형_통합'] = train['시술 유형'].astype(str) + '_' + train['세부 시술 유형'].astype(str)\n",
    "    test['시술유형_통합'] = test['시술 유형'].astype(str) + '_' + test['세부 시술 유형'].astype(str)\n",
    "\n",
    "    drop_cols = ['시술 유형', '세부 시술 유형']\n",
    "    train = train.drop(drop_cols, axis=1)\n",
    "    test = test.drop(drop_cols, axis=1)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def 횟수_to_int(df_train, df_val):\n",
    "    for col in [col for col in df_train.columns if '횟수' in col]:\n",
    "        df_train[col] = df_train[col].replace({'6회 이상': '6회'})\n",
    "        df_val[col] = df_val[col].replace({'6회 이상': '6회'})\n",
    "\n",
    "        df_train[col] = df_train[col].str[0].astype(int)\n",
    "        df_val[col] = df_val[col].str[0].astype(int)\n",
    "\n",
    "    return df_train, df_val\n",
    "\n",
    "def 임신_IVF(df_train, df_val):\n",
    "    for col in [col for col in df_train.columns if '횟수' in col]:\n",
    "        df_train[col] = df_train[col].replace({'6회 이상': '6회'})\n",
    "        df_val[col] = df_val[col].replace({'6회 이상': '6회'})\n",
    "        mode_value = df_train[col].mode()[0]\n",
    "\n",
    "        df_train[col] = df_train[col].fillna(mode_value)\n",
    "        df_val[col] = df_val[col].fillna(mode_value)\n",
    "\n",
    "        # 문자열의 첫 글자를 추출 후 int형으로 변환\n",
    "        df_train[col] = df_train[col].str[0].astype(int)\n",
    "        df_val[col] = df_val[col].str[0].astype(int)\n",
    "\n",
    "    df_train['임신_IVF'] = df_train['이전 총 임신 횟수'] - df_train['이전 IVF 시술 횟수']\n",
    "    df_val['임신_IVF'] = df_val['이전 총 임신 횟수'] - df_val['이전 IVF 시술 횟수']\n",
    "    # df_train = df_train.drop('이전 시술 횟수', axis=1)\n",
    "    return df_train, df_val\n",
    "\n",
    "\n",
    "def 난자기증자나이(df_train, df_test):\n",
    "    mapping = {\n",
    "        '만20세 이하': 20,\n",
    "        '만21-25세': 25,\n",
    "        '만26-30세': 30,\n",
    "        '만31-35세': 35,\n",
    "        '알 수 없음': 20,  # 만20세 이하와 동일하게 처리\n",
    "    }\n",
    "    df_train['난자 기증자 나이'] = df_train['난자 기증자 나이'].replace(mapping)\n",
    "    df_test['난자 기증자 나이'] = df_test['난자 기증자 나이'].replace(mapping)\n",
    "    return df_train, df_test\n",
    "\n",
    "def 단일배아이식여부(df_train, df_val):\n",
    "    df_train['단일 배아 이식 여부'] = df_train['단일 배아 이식 여부'].fillna(0)\n",
    "    df_val['단일 배아 이식 여부'] = df_val['단일 배아 이식 여부'].fillna(0)\n",
    "    return df_train, df_val\n",
    "\n",
    "\n",
    "def 기증자정자와혼합된난자수(df_train, df_test):\n",
    "    df_train[\"기증자 정자와 혼합된 난자 수\"] = df_train[\"기증자 정자와 혼합된 난자 수\"].fillna(2)\n",
    "    df_test[\"기증자 정자와 혼합된 난자 수\"] = df_test[\"기증자 정자와 혼합된 난자 수\"].fillna(2)\n",
    "    return df_train, df_test\n",
    "\n",
    "def label_encoding(train, test, cols):\n",
    "    encoder = LabelEncoder()\n",
    "    for col in cols:\n",
    "        train[col] = encoder.fit_transform(train[col])\n",
    "        test[col] = encoder.transform(test[col])\n",
    "    return train, test\n",
    "\n",
    "def type_to_category(train, test, cols):\n",
    "    train[cols] = train[cols].astype('category')\n",
    "    test[cols] = test[cols].astype('category')\n",
    "    return train, test\n",
    "\n",
    "def impute_nan(train, test):\n",
    "\n",
    "    for col in cols_to_impute:\n",
    "        train[col] = train[col].fillna(0)\n",
    "        test[col] = test[col].fillna(0)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def num_feature_scailing(train, test, seed=777):\n",
    "    cat_cols = [col for col in train.columns if pd.api.types.is_categorical_dtype(train[col])]\n",
    "    numeric_cols = [col for col in train.columns if col not in cat_cols and col != '임신 성공 확률']\n",
    "    # bin_cols 들도 동일하게 스케일링\n",
    "\n",
    "    arr_train = train[numeric_cols].to_numpy()  # DataFrame -> NumPy\n",
    "    arr_train = arr_train.astype(np.float32)\n",
    "    arr_test = test[numeric_cols].to_numpy()\n",
    "    arr_test = arr_test.astype(np.float32)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    noise = (\n",
    "        np.random.default_rng(0)\n",
    "        .normal(0.0, 1e-5, arr_train.shape)\n",
    "        .astype(arr_train.dtype)\n",
    "    )\n",
    "    preprocessing = QuantileTransformer(\n",
    "        n_quantiles=max(min(len(train[numeric_cols]) // 30, 1000), 10),\n",
    "        output_distribution='normal',\n",
    "        subsample=10**9,\n",
    "    ).fit(arr_train + noise)\n",
    "\n",
    "    train[numeric_cols] = preprocessing.transform(arr_train)\n",
    "    test[numeric_cols] = preprocessing.transform(arr_test)\n",
    "    return train, test\n",
    "\n",
    "def drop_single_value_columns(df_train, df_test):\n",
    "    cols_to_drop = [col for col in df_train.columns if df_train[col].nunique() == 1]\n",
    "    return df_train.drop(columns=cols_to_drop), df_test.drop(columns=cols_to_drop)\n",
    "\n",
    "def all_process(train, val):\n",
    "    train, val = drop_cols_with_na(train, val)\n",
    "\n",
    "    # 기본 전처리 단계\n",
    "    train, val = 횟수_to_int(train, val)\n",
    "\n",
    "    train, val = 시술유형(train, val)\n",
    "    # train, val = 임신_IVF(train, val)\n",
    "\n",
    "    train, val = 단일배아이식여부(train, val)\n",
    "\n",
    "    cols_to_encoding = [\n",
    "        \"환자 시술 당시 나이\",\n",
    "        # \"클리닉 내 총 시술 횟수\",\n",
    "        # \"IVF 시술 횟수\",\n",
    "        # \"DI 시술 횟수\",\n",
    "        # \"총 임신 횟수\",\n",
    "        # \"IVF 임신 횟수\",\n",
    "        # \"DI 임신 횟수\",\n",
    "        # \"총 출산 횟수\",\n",
    "        # \"IVF 출산 횟수\",\n",
    "        # \"DI 출산 횟수\",\n",
    "        \"난자 출처\",\n",
    "        \"정자 출처\",\n",
    "        \"난자 기증자 나이\",\n",
    "        \"정자 기증자 나이\",\n",
    "        '시술유형_통합',\n",
    "\n",
    "        '해동된 배아 수', # 원래 int였는데 범주형으로 바뀜\n",
    "\n",
    "    ]\n",
    "    train, val = label_encoding(train, val, cols=cols_to_encoding)\n",
    "    train, val = type_to_category(train, val, cols=cols_to_encoding)\n",
    "\n",
    "    # train, val = impute_nan(train, val)\n",
    "    train, val = num_feature_scailing(train, val)\n",
    "\n",
    "    train, val = drop_single_value_columns(train, val)\n",
    "\n",
    "    return train, val\n"
   ],
   "id": "7636a6caa42dca45",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T10:55:38.115517Z",
     "start_time": "2025-04-05T10:55:36.913682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from preprocess_DL import all_process\n",
    "\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "train, test = all_process(train, test)\n",
    "\n",
    "print(train.shape, test.shape)"
   ],
   "id": "d931c6a8384f4e1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126244, 24) (54412, 23)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T10:55:38.162517Z",
     "start_time": "2025-04-05T10:55:38.132517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_cols(df_train, target_col='임신 성공 확률'):\n",
    "    cat_cols = [col for col in df_train.columns if pd.api.types.is_categorical_dtype(df_train[col])]\n",
    "    numeric_cols = [col for col in df_train.columns if col not in cat_cols and col != '임신 성공 확률']\n",
    "\n",
    "    num_cols = []\n",
    "    bin_cols = []\n",
    "    for col in numeric_cols:\n",
    "        if df_train[col].nunique() == 2:\n",
    "            bin_cols.append(col)\n",
    "        else:\n",
    "            num_cols.append(col)\n",
    "\n",
    "    return num_cols, bin_cols, cat_cols\n",
    "\n",
    "num_cols, bin_cols, cat_cols = get_cols(train)\n",
    "cat_cardinalities = [train[col].nunique() for col in cat_cols]\n",
    "\n",
    "print(f'수치형 변수: {len(num_cols)}개 \\n{num_cols}')\n",
    "print(f'이진형 변수: {len(bin_cols)}개 \\n{bin_cols}')\n",
    "print(f'범주형 변수: {len(cat_cols)}개 \\n{cat_cols}')"
   ],
   "id": "9dbb80b9a10a8558",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수치형 변수: 2개 \n",
      "['이전 IVF 시술 횟수', '이전 DI 시술 횟수']\n",
      "이진형 변수: 14개 \n",
      "['배란 자극 시술 여부', '단일 배아 이식 여부', '불임 원인 - 난관 질환', '불임 원인 - 배란 장애', '불임 원인 - 남성 요인', '불임 원인 - 자궁내막증', '불임 원인 - 불명확', '해동 난자 사용 여부', '신선 난자 사용 여부', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '착상 전 PGD 시행 여부', '착상 전 PGS 시행 여부']\n",
      "범주형 변수: 7개 \n",
      "['환자 시술 당시 나이', '해동된 배아 수', '난자 출처', '정자 출처', '난자 기증자 나이', '정자 기증자 나이', '시술유형_통합']\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T10:55:38.193517Z",
     "start_time": "2025-04-05T10:55:38.178516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_dataset_from_dfs(train_df, valid_df, test_df, num_cols, bin_cols, cat_cols, target_col='임신 성공 확률'):\n",
    "    data = {}\n",
    "    data['X_num'] = {\n",
    "        'train': torch.tensor(train_df[num_cols].values, dtype=torch.float32),\n",
    "        'val':   torch.tensor(valid_df[num_cols].values, dtype=torch.float32),\n",
    "        'test':  torch.tensor(test_df[num_cols].values, dtype=torch.float32),\n",
    "    }\n",
    "    data['X_bin'] = {\n",
    "        'train': torch.tensor(train_df[bin_cols].values, dtype=torch.float32),\n",
    "        'val':   torch.tensor(valid_df[bin_cols].values, dtype=torch.float32),\n",
    "        'test':  torch.tensor(test_df[bin_cols].values, dtype=torch.float32),\n",
    "    }\n",
    "    if cat_cols:\n",
    "        data['X_cat'] = {\n",
    "            'train': torch.tensor(train_df[cat_cols].values, dtype=torch.long),\n",
    "            'val':   torch.tensor(valid_df[cat_cols].values, dtype=torch.long),\n",
    "            'test':  torch.tensor(test_df[cat_cols].values, dtype=torch.long),\n",
    "        }\n",
    "    else:\n",
    "        data['X_cat'] = None\n",
    "    data['Y'] = {\n",
    "        'train': torch.tensor(train_df[target_col].values, dtype=torch.float),\n",
    "        'val':   torch.tensor(valid_df[target_col].values, dtype=torch.float),\n",
    "        # test 데이터에는 타깃이 없을 수 있습니다.\n",
    "    }\n",
    "    return data\n",
    "\n",
    "def move_data_to_device(data, device):\n",
    "    # data는 dict 형식: 예) {'X_num': {'train': tensor, 'val': tensor, ...}, ...}\n",
    "    for key in data:\n",
    "        if data[key] is None:\n",
    "            continue\n",
    "        if isinstance(data[key], dict):\n",
    "            for part in data[key]:\n",
    "                data[key][part] = data[key][part].to(device)\n",
    "        else:\n",
    "            data[key] = data[key].to(device)\n",
    "    return data\n",
    "\n",
    "\n",
    "class MyDataset:\n",
    "    def __init__(self, data, n_num_features, n_bin_features, cat_cardinalities, is_regression=False, is_multiclass=True):\n",
    "        self.data = data\n",
    "        self._n_num_features = n_num_features\n",
    "        self._n_bin_features = n_bin_features\n",
    "        self._cat_cardinalities = cat_cardinalities\n",
    "        self.is_regression = is_regression\n",
    "        self.is_multiclass = is_multiclass\n",
    "\n",
    "    @property\n",
    "    def n_num_features(self):\n",
    "        return self._n_num_features\n",
    "\n",
    "    @property\n",
    "    def n_bin_features(self):\n",
    "        return self._n_bin_features\n",
    "\n",
    "    def cat_cardinalities(self):\n",
    "        return self._cat_cardinalities\n",
    "\n",
    "    @property\n",
    "    def Y(self):\n",
    "        return self.data['Y']\n",
    "\n",
    "    def size(self, part: str) -> int:\n",
    "        # target이 있는 경우 사용\n",
    "        if part in self.data['Y']:\n",
    "            return self.data['Y'][part].shape[0]\n",
    "        else:\n",
    "            return self.data['X_num'][part].shape[0]\n",
    "\n",
    "# data_dict = build_dataset_from_dfs(train, valid, test, num_cols, bin_cols, cat_cols, target_col='임신 성공 확률')\n",
    "# data_dict = move_data_to_device(data_dict, device)\n",
    "#\n",
    "# dataset = MyDataset(data_dict, n_num_features=len(num_cols), n_bin_features=len(bin_cols), cat_cardinalities=cat_cardinalities)"
   ],
   "id": "cf40ff609df1c64b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T10:55:38.224516Z",
     "start_time": "2025-04-05T10:55:38.210519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_Xy(part: str, idx: torch.Tensor = None) -> tuple[dict, torch.Tensor]:\n",
    "    batch = (\n",
    "        { key[2:]: dataset.data[key][part] for key in dataset.data if key.startswith('X_') },\n",
    "        dataset.data['Y'][part] if 'Y' in dataset.data and part in dataset.data['Y'] else None\n",
    "    )\n",
    "    if idx is None:\n",
    "        return batch\n",
    "    else:\n",
    "        return (\n",
    "            {k: v[idx] for k, v in batch[0].items()},\n",
    "            batch[1][idx] if batch[1] is not None else None\n",
    "        )\n",
    "\n",
    "# train_size = dataset.size('train')\n",
    "# train_indices = torch.arange(train_size, device=device)"
   ],
   "id": "691e8030d5feac88",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T10:55:39.282789Z",
     "start_time": "2025-04-05T10:55:38.242516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Model(\n",
    "    n_num_features=len(num_cols),\n",
    "    n_bin_features=len(bin_cols),\n",
    "    cat_cardinalities=cat_cardinalities,\n",
    "    n_classes=1,\n",
    "    num_embeddings=None,      # 임베딩 사용하지 않을 경우 None\n",
    "    d_main=64,\n",
    "    d_multiplier=2.0,\n",
    "    encoder_n_blocks=2,\n",
    "    predictor_n_blocks=2,\n",
    "    mixer_normalization=True,\n",
    "    context_dropout=0.1,\n",
    "    dropout0=0.1,\n",
    "    dropout1='dropout0',      # 'dropout0' 문자열을 지정하면 내부에서 dropout0 값이 사용됩니다.\n",
    "    normalization=\"BatchNorm1d\",\n",
    "    activation=\"ReLU\",\n",
    "    memory_efficient=False,\n",
    "    candidate_encoding_batch_size=None,\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ],
   "id": "d52517b7938dcaf7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T10:55:39.313788Z",
     "start_time": "2025-04-05T10:55:39.299788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_model(part: str, idx: torch.Tensor, is_train: bool) -> torch.Tensor:\n",
    "    x, y = get_Xy(part, idx)\n",
    "    candidate_indices = train_indices\n",
    "    if is_train:\n",
    "        # training part: 후보에서 현재 배치 제거\n",
    "        candidate_indices = candidate_indices[~torch.isin(candidate_indices, idx)]\n",
    "    # 후보 데이터: 조건에 따라 전체 train 또는 선택된 인덱스 사용\n",
    "    candidate_x, candidate_y = get_Xy('train', None if candidate_indices.equal(train_indices) else candidate_indices)\n",
    "    return model(\n",
    "        x_=x,\n",
    "        y=y if is_train else None,\n",
    "        candidate_x_=candidate_x,\n",
    "        candidate_y=candidate_y,\n",
    "        context_size=5,\n",
    "        is_train=is_train,\n",
    "    ).squeeze(-1)\n"
   ],
   "id": "582b27aec832b9a",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T11:05:41.857346Z",
     "start_time": "2025-04-05T11:03:31.480027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed = 333\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "delu.random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "test_preds = []\n",
    "val_scores = []\n",
    "\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train)):\n",
    "    fold_train = train.iloc[train_idx].copy().reset_index(drop=True)\n",
    "    fold_valid = train.iloc[valid_idx].copy().reset_index(drop=True)\n",
    "    fold_train2 = fold_train.copy()\n",
    "    fold_test = test.copy()\n",
    "\n",
    "    fold_train, fold_valid = all_process(fold_train, fold_valid)\n",
    "    _, fold_test = all_process(fold_train2, fold_test)\n",
    "\n",
    "    num_cols, bin_cols, cat_cols = get_cols(fold_train)\n",
    "    cat_cardinalities = [fold_train[col].nunique() for col in cat_cols]\n",
    "\n",
    "    data_dict = build_dataset_from_dfs(\n",
    "        fold_train, fold_valid, fold_test,\n",
    "        num_cols, bin_cols, cat_cols, target_col='임신 성공 확률'\n",
    "    )\n",
    "    data_dict = move_data_to_device(data_dict, device)\n",
    "    dataset = MyDataset(data_dict, n_num_features=len(num_cols), n_bin_features=len(bin_cols), cat_cardinalities=cat_cardinalities)\n",
    "\n",
    "    train_size = dataset.size('train')\n",
    "    train_indices = torch.arange(train_size, device=device)\n",
    "\n",
    "    model = Model(\n",
    "        n_num_features=len(num_cols),\n",
    "        n_bin_features=len(bin_cols),\n",
    "        cat_cardinalities=cat_cardinalities,\n",
    "        n_classes=None,\n",
    "        num_embeddings=None,      # 임베딩 사용하지 않을 경우 None\n",
    "        d_main=64,\n",
    "        d_multiplier=2.0,\n",
    "        encoder_n_blocks=2,\n",
    "        predictor_n_blocks=2,\n",
    "        mixer_normalization=True,\n",
    "        context_dropout=0.1,\n",
    "        dropout0=0.1,\n",
    "        dropout1='dropout0',      # 'dropout0' 문자열을 지정하면 내부에서 dropout0 값이 사용됩니다.\n",
    "        normalization=\"BatchNorm1d\",\n",
    "        activation=\"ReLU\",\n",
    "        memory_efficient=False,\n",
    "        candidate_encoding_batch_size=None,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    num_epochs = 100000\n",
    "    batch_size = 2048\n",
    "\n",
    "    patience = 10\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    checkpoint_path = \"best_model_TabR.pth\"\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        shuffled_indices = train_indices[torch.randperm(train_size)]\n",
    "        num_batches = math.ceil(train_size / batch_size)\n",
    "        epoch_loss = 0.0\n",
    "        for i in range(num_batches):\n",
    "            idx = shuffled_indices[i * batch_size : (i + 1) * batch_size]\n",
    "            outputs = apply_model('train', idx, is_train=True)\n",
    "\n",
    "            # 해당 인덱스의 타깃\n",
    "            _, y_batch = get_Xy('train', idx)\n",
    "\n",
    "            y_batch = y_batch.float()\n",
    "            loss = criterion(outputs.squeeze(), y_batch.squeeze()) # squeeze해서 shape 맞추기 (예: (batch_size,))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * idx.numel()\n",
    "\n",
    "        avg_loss = epoch_loss / train_size\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_indices = torch.arange(dataset.size('val'), device=device)\n",
    "            outputs_val = apply_model('val', val_indices, is_train=False)\n",
    "            _, y_val = get_Xy('val', val_indices)\n",
    "\n",
    "            val_loss = criterion(outputs_val.squeeze(), y_val.float().squeeze()).item() # validation loss 계산\n",
    "\n",
    "            outputs_val_np = outputs_val.detach().cpu().numpy().squeeze()\n",
    "            outputs_val_np = np.clip(outputs_val_np, 0, 1)\n",
    "            y_val_np = y_val.detach().cpu().numpy().squeeze()\n",
    "\n",
    "            val_score = competition_metric(y_val_np, outputs_val_np)\n",
    "            val_scores.append(val_score)\n",
    "        print(f\"[Epoch {epoch+1}] Train Loss: {avg_loss:.4f}, Valid Loss: {val_loss:.4f}, Valid Score: {val_score:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stop_counter = 0\n",
    "            best = {'epoch': epoch+1, 'train_loss':avg_loss, 'val_loss': val_loss, 'val_score': val_score}\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            # print(f\"No improvement in validation loss for {early_stop_counter} epochs.\")\n",
    "            if early_stop_counter >= patience:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f'\\n[Fold{fold+1} Result]')\n",
    "    print(best)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_indices = torch.arange(dataset.size('test'), device=device)\n",
    "        test_pred = apply_model('test', test_indices, is_train=False)\n",
    "        test_pred_np = test_pred.detach().cpu().numpy().squeeze()\n",
    "        test_preds.append(test_pred_np)\n",
    "\n",
    "\n",
    "avg_valid_score = np.mean(val_scores, axis=0)\n",
    "\n",
    "print(f'[Seed {seed}] Final Valid Score: {avg_valid_score}')"
   ],
   "id": "7a2e4dcbc4842d7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.2258, Valid Loss: 0.1680, Valid AUC: 0.396055\n",
      "[Epoch 2] Train Loss: 0.1702, Valid Loss: 0.1641, Valid AUC: 0.380258\n",
      "[Epoch 3] Train Loss: 0.1670, Valid Loss: 0.1629, Valid AUC: 0.365977\n",
      "[Epoch 4] Train Loss: 0.1656, Valid Loss: 0.1628, Valid AUC: 0.359220\n",
      "[Epoch 5] Train Loss: 0.1644, Valid Loss: 0.1633, Valid AUC: 0.386130\n",
      "[Epoch 6] Train Loss: 0.1640, Valid Loss: 0.1627, Valid AUC: 0.361295\n",
      "[Epoch 7] Train Loss: 0.1639, Valid Loss: 0.1626, Valid AUC: 0.364489\n",
      "[Epoch 8] Train Loss: 0.1635, Valid Loss: 0.1626, Valid AUC: 0.358539\n",
      "[Epoch 9] Train Loss: 0.1628, Valid Loss: 0.1627, Valid AUC: 0.370576\n",
      "[Epoch 10] Train Loss: 0.1631, Valid Loss: 0.1628, Valid AUC: 0.371270\n",
      "[Epoch 11] Train Loss: 0.1629, Valid Loss: 0.1625, Valid AUC: 0.361044\n",
      "[Epoch 12] Train Loss: 0.1627, Valid Loss: 0.1630, Valid AUC: 0.380371\n",
      "[Epoch 13] Train Loss: 0.1625, Valid Loss: 0.1637, Valid AUC: 0.374815\n",
      "[Epoch 14] Train Loss: 0.1624, Valid Loss: 0.1623, Valid AUC: 0.359373\n",
      "[Epoch 15] Train Loss: 0.1622, Valid Loss: 0.1624, Valid AUC: 0.368818\n",
      "[Epoch 16] Train Loss: 0.1621, Valid Loss: 0.1627, Valid AUC: 0.375138\n",
      "[Epoch 17] Train Loss: 0.1622, Valid Loss: 0.1623, Valid AUC: 0.370775\n",
      "[Epoch 18] Train Loss: 0.1621, Valid Loss: 0.1624, Valid AUC: 0.363153\n",
      "[Epoch 19] Train Loss: 0.1619, Valid Loss: 0.1632, Valid AUC: 0.374138\n",
      "[Epoch 20] Train Loss: 0.1620, Valid Loss: 0.1624, Valid AUC: 0.359416\n",
      "[Epoch 21] Train Loss: 0.1618, Valid Loss: 0.1629, Valid AUC: 0.359988\n",
      "[Epoch 22] Train Loss: 0.1618, Valid Loss: 0.1626, Valid AUC: 0.371177\n",
      "[Epoch 23] Train Loss: 0.1616, Valid Loss: 0.1629, Valid AUC: 0.384446\n",
      "[Epoch 24] Train Loss: 0.1615, Valid Loss: 0.1626, Valid AUC: 0.370540\n",
      "\n",
      "[Fold1 Result]\n",
      "{'epoch': 14, 'train_loss': 0.16235375457724413, 'val_loss': 0.16226722300052643, 'val_auc': 0.3593732947320269}\n",
      "[Epoch 1] Train Loss: 0.3029, Valid Loss: 0.1658, Valid AUC: 0.351208\n",
      "[Epoch 2] Train Loss: 0.1702, Valid Loss: 0.1623, Valid AUC: 0.363567\n",
      "[Epoch 3] Train Loss: 0.1679, Valid Loss: 0.1617, Valid AUC: 0.356195\n",
      "[Epoch 4] Train Loss: 0.1667, Valid Loss: 0.1613, Valid AUC: 0.359108\n",
      "[Epoch 5] Train Loss: 0.1654, Valid Loss: 0.1623, Valid AUC: 0.385703\n",
      "[Epoch 6] Train Loss: 0.1646, Valid Loss: 0.1613, Valid AUC: 0.368342\n",
      "[Epoch 7] Train Loss: 0.1644, Valid Loss: 0.1613, Valid AUC: 0.377080\n",
      "[Epoch 8] Train Loss: 0.1643, Valid Loss: 0.1611, Valid AUC: 0.361671\n",
      "[Epoch 9] Train Loss: 0.1637, Valid Loss: 0.1616, Valid AUC: 0.367938\n",
      "[Epoch 10] Train Loss: 0.1636, Valid Loss: 0.1611, Valid AUC: 0.367244\n",
      "[Epoch 11] Train Loss: 0.1634, Valid Loss: 0.1609, Valid AUC: 0.360650\n",
      "[Epoch 12] Train Loss: 0.1633, Valid Loss: 0.1610, Valid AUC: 0.372025\n",
      "[Epoch 13] Train Loss: 0.1633, Valid Loss: 0.1610, Valid AUC: 0.361330\n",
      "[Epoch 14] Train Loss: 0.1629, Valid Loss: 0.1608, Valid AUC: 0.368199\n",
      "[Epoch 15] Train Loss: 0.1628, Valid Loss: 0.1612, Valid AUC: 0.373363\n",
      "[Epoch 16] Train Loss: 0.1629, Valid Loss: 0.1611, Valid AUC: 0.362132\n",
      "[Epoch 17] Train Loss: 0.1627, Valid Loss: 0.1609, Valid AUC: 0.363101\n",
      "[Epoch 18] Train Loss: 0.1628, Valid Loss: 0.1609, Valid AUC: 0.366968\n",
      "[Epoch 19] Train Loss: 0.1626, Valid Loss: 0.1609, Valid AUC: 0.361499\n",
      "[Epoch 20] Train Loss: 0.1625, Valid Loss: 0.1611, Valid AUC: 0.371987\n",
      "[Epoch 21] Train Loss: 0.1625, Valid Loss: 0.1612, Valid AUC: 0.370526\n",
      "[Epoch 22] Train Loss: 0.1624, Valid Loss: 0.1610, Valid AUC: 0.372402\n",
      "[Epoch 23] Train Loss: 0.1622, Valid Loss: 0.1611, Valid AUC: 0.367559\n",
      "[Epoch 24] Train Loss: 0.1625, Valid Loss: 0.1615, Valid AUC: 0.384722\n",
      "\n",
      "[Fold2 Result]\n",
      "{'epoch': 14, 'train_loss': 0.16294968403373072, 'val_loss': 0.1608479768037796, 'val_auc': 0.36819890778674824}\n",
      "[Epoch 1] Train Loss: 0.1880, Valid Loss: 0.1673, Valid AUC: 0.400399\n",
      "[Epoch 2] Train Loss: 0.1684, Valid Loss: 0.1644, Valid AUC: 0.359533\n",
      "[Epoch 3] Train Loss: 0.1663, Valid Loss: 0.1639, Valid AUC: 0.364878\n",
      "[Epoch 4] Train Loss: 0.1647, Valid Loss: 0.1639, Valid AUC: 0.361276\n",
      "[Epoch 5] Train Loss: 0.1640, Valid Loss: 0.1636, Valid AUC: 0.358184\n",
      "[Epoch 6] Train Loss: 0.1636, Valid Loss: 0.1634, Valid AUC: 0.361283\n",
      "[Epoch 7] Train Loss: 0.1633, Valid Loss: 0.1635, Valid AUC: 0.360280\n",
      "[Epoch 8] Train Loss: 0.1630, Valid Loss: 0.1634, Valid AUC: 0.357549\n",
      "[Epoch 9] Train Loss: 0.1625, Valid Loss: 0.1634, Valid AUC: 0.370869\n",
      "[Epoch 10] Train Loss: 0.1624, Valid Loss: 0.1634, Valid AUC: 0.357279\n",
      "[Epoch 11] Train Loss: 0.1622, Valid Loss: 0.1639, Valid AUC: 0.361727\n",
      "[Epoch 12] Train Loss: 0.1621, Valid Loss: 0.1636, Valid AUC: 0.366451\n",
      "[Epoch 13] Train Loss: 0.1621, Valid Loss: 0.1633, Valid AUC: 0.364629\n",
      "[Epoch 14] Train Loss: 0.1620, Valid Loss: 0.1636, Valid AUC: 0.382860\n",
      "[Epoch 15] Train Loss: 0.1618, Valid Loss: 0.1634, Valid AUC: 0.361723\n",
      "[Epoch 16] Train Loss: 0.1618, Valid Loss: 0.1633, Valid AUC: 0.374829\n",
      "[Epoch 17] Train Loss: 0.1616, Valid Loss: 0.1633, Valid AUC: 0.368704\n",
      "[Epoch 18] Train Loss: 0.1616, Valid Loss: 0.1635, Valid AUC: 0.360743\n",
      "[Epoch 19] Train Loss: 0.1614, Valid Loss: 0.1635, Valid AUC: 0.363880\n",
      "[Epoch 20] Train Loss: 0.1615, Valid Loss: 0.1636, Valid AUC: 0.358284\n",
      "[Epoch 21] Train Loss: 0.1611, Valid Loss: 0.1636, Valid AUC: 0.365160\n",
      "[Epoch 22] Train Loss: 0.1615, Valid Loss: 0.1636, Valid AUC: 0.380162\n",
      "[Epoch 23] Train Loss: 0.1611, Valid Loss: 0.1635, Valid AUC: 0.366947\n",
      "[Epoch 24] Train Loss: 0.1611, Valid Loss: 0.1633, Valid AUC: 0.369621\n",
      "[Epoch 25] Train Loss: 0.1611, Valid Loss: 0.1636, Valid AUC: 0.366081\n",
      "[Epoch 26] Train Loss: 0.1610, Valid Loss: 0.1635, Valid AUC: 0.362692\n",
      "[Epoch 27] Train Loss: 0.1609, Valid Loss: 0.1633, Valid AUC: 0.364788\n",
      "\n",
      "[Fold3 Result]\n",
      "{'epoch': 17, 'train_loss': 0.1616235203746286, 'val_loss': 0.16328011453151703, 'val_auc': 0.3687037089257118}\n",
      "[Epoch 1] Train Loss: 0.1883, Valid Loss: 0.1656, Valid AUC: 0.378393\n",
      "[Epoch 2] Train Loss: 0.1676, Valid Loss: 0.1643, Valid AUC: 0.377360\n",
      "[Epoch 3] Train Loss: 0.1650, Valid Loss: 0.1632, Valid AUC: 0.366463\n",
      "[Epoch 4] Train Loss: 0.1642, Valid Loss: 0.1639, Valid AUC: 0.377522\n",
      "[Epoch 5] Train Loss: 0.1637, Valid Loss: 0.1631, Valid AUC: 0.372040\n",
      "[Epoch 6] Train Loss: 0.1632, Valid Loss: 0.1630, Valid AUC: 0.364518\n",
      "[Epoch 7] Train Loss: 0.1627, Valid Loss: 0.1632, Valid AUC: 0.372714\n",
      "[Epoch 8] Train Loss: 0.1625, Valid Loss: 0.1629, Valid AUC: 0.365153\n",
      "[Epoch 9] Train Loss: 0.1625, Valid Loss: 0.1626, Valid AUC: 0.368709\n",
      "[Epoch 10] Train Loss: 0.1624, Valid Loss: 0.1628, Valid AUC: 0.371579\n",
      "[Epoch 11] Train Loss: 0.1622, Valid Loss: 0.1630, Valid AUC: 0.363120\n",
      "[Epoch 12] Train Loss: 0.1619, Valid Loss: 0.1629, Valid AUC: 0.367373\n",
      "[Epoch 13] Train Loss: 0.1618, Valid Loss: 0.1631, Valid AUC: 0.377618\n",
      "[Epoch 14] Train Loss: 0.1621, Valid Loss: 0.1632, Valid AUC: 0.388645\n",
      "[Epoch 15] Train Loss: 0.1619, Valid Loss: 0.1627, Valid AUC: 0.371238\n",
      "[Epoch 16] Train Loss: 0.1616, Valid Loss: 0.1626, Valid AUC: 0.363725\n",
      "[Epoch 17] Train Loss: 0.1615, Valid Loss: 0.1630, Valid AUC: 0.369437\n",
      "[Epoch 18] Train Loss: 0.1614, Valid Loss: 0.1626, Valid AUC: 0.371292\n",
      "[Epoch 19] Train Loss: 0.1614, Valid Loss: 0.1629, Valid AUC: 0.374673\n",
      "[Epoch 20] Train Loss: 0.1613, Valid Loss: 0.1629, Valid AUC: 0.370208\n",
      "[Epoch 21] Train Loss: 0.1613, Valid Loss: 0.1633, Valid AUC: 0.361958\n",
      "[Epoch 22] Train Loss: 0.1611, Valid Loss: 0.1632, Valid AUC: 0.370497\n",
      "[Epoch 23] Train Loss: 0.1610, Valid Loss: 0.1628, Valid AUC: 0.376194\n",
      "[Epoch 24] Train Loss: 0.1610, Valid Loss: 0.1633, Valid AUC: 0.373501\n",
      "[Epoch 25] Train Loss: 0.1610, Valid Loss: 0.1633, Valid AUC: 0.365847\n",
      "[Epoch 26] Train Loss: 0.1609, Valid Loss: 0.1631, Valid AUC: 0.389506\n",
      "\n",
      "[Fold4 Result]\n",
      "{'epoch': 16, 'train_loss': 0.1615747690066541, 'val_loss': 0.1625559777021408, 'val_auc': 0.36372473964570384}\n",
      "[Epoch 1] Train Loss: 0.1931, Valid Loss: 0.1674, Valid AUC: 0.379089\n",
      "[Epoch 2] Train Loss: 0.1686, Valid Loss: 0.1650, Valid AUC: 0.375900\n",
      "[Epoch 3] Train Loss: 0.1661, Valid Loss: 0.1647, Valid AUC: 0.368226\n",
      "[Epoch 4] Train Loss: 0.1646, Valid Loss: 0.1637, Valid AUC: 0.360339\n",
      "[Epoch 5] Train Loss: 0.1640, Valid Loss: 0.1639, Valid AUC: 0.360496\n",
      "[Epoch 6] Train Loss: 0.1635, Valid Loss: 0.1640, Valid AUC: 0.360427\n",
      "[Epoch 7] Train Loss: 0.1629, Valid Loss: 0.1636, Valid AUC: 0.373369\n",
      "[Epoch 8] Train Loss: 0.1626, Valid Loss: 0.1638, Valid AUC: 0.360328\n",
      "[Epoch 9] Train Loss: 0.1625, Valid Loss: 0.1637, Valid AUC: 0.373140\n",
      "[Epoch 10] Train Loss: 0.1625, Valid Loss: 0.1639, Valid AUC: 0.371270\n",
      "[Epoch 11] Train Loss: 0.1623, Valid Loss: 0.1637, Valid AUC: 0.369066\n",
      "[Epoch 12] Train Loss: 0.1622, Valid Loss: 0.1643, Valid AUC: 0.366740\n",
      "[Epoch 13] Train Loss: 0.1619, Valid Loss: 0.1646, Valid AUC: 0.354588\n",
      "[Epoch 14] Train Loss: 0.1619, Valid Loss: 0.1641, Valid AUC: 0.368666\n",
      "[Epoch 15] Train Loss: 0.1618, Valid Loss: 0.1638, Valid AUC: 0.363757\n",
      "[Epoch 16] Train Loss: 0.1618, Valid Loss: 0.1644, Valid AUC: 0.354947\n",
      "[Epoch 17] Train Loss: 0.1616, Valid Loss: 0.1635, Valid AUC: 0.359286\n",
      "[Epoch 18] Train Loss: 0.1614, Valid Loss: 0.1643, Valid AUC: 0.377884\n",
      "[Epoch 19] Train Loss: 0.1614, Valid Loss: 0.1637, Valid AUC: 0.365711\n",
      "[Epoch 20] Train Loss: 0.1613, Valid Loss: 0.1643, Valid AUC: 0.372982\n",
      "[Epoch 21] Train Loss: 0.1612, Valid Loss: 0.1636, Valid AUC: 0.363633\n",
      "[Epoch 22] Train Loss: 0.1612, Valid Loss: 0.1645, Valid AUC: 0.366532\n",
      "[Epoch 23] Train Loss: 0.1611, Valid Loss: 0.1636, Valid AUC: 0.364944\n",
      "[Epoch 24] Train Loss: 0.1610, Valid Loss: 0.1636, Valid AUC: 0.369223\n",
      "[Epoch 25] Train Loss: 0.1610, Valid Loss: 0.1641, Valid AUC: 0.359155\n",
      "[Epoch 26] Train Loss: 0.1610, Valid Loss: 0.1637, Valid AUC: 0.367558\n",
      "[Epoch 27] Train Loss: 0.1607, Valid Loss: 0.1637, Valid AUC: 0.379064\n",
      "\n",
      "[Fold5 Result]\n",
      "{'epoch': 17, 'train_loss': 0.16157112139605773, 'val_loss': 0.16351422667503357, 'val_auc': 0.35928644533166076}\n",
      "[Seed 333] Final Test AUC: 0.36849946427717273\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T11:06:56.119026Z",
     "start_time": "2025-04-05T11:06:56.088026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "submission = pd.read_csv(sample_path)\n",
    "\n",
    "submission['임신 성공 확률'] = np.clip(np.mean(test_preds, axis=0), 0, 1)\n",
    "submission"
   ],
   "id": "29e90998823c991c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               ID  임신 성공 확률\n",
       "0      TEST_00000  0.073774\n",
       "1      TEST_00001  0.183785\n",
       "2      TEST_00002  0.219433\n",
       "3      TEST_00003  0.283400\n",
       "4      TEST_00004  0.254783\n",
       "...           ...       ...\n",
       "54407  TEST_54407  0.287154\n",
       "54408  TEST_54408  0.014109\n",
       "54409  TEST_54409  0.293662\n",
       "54410  TEST_54410  0.270870\n",
       "54411  TEST_54411  0.160930\n",
       "\n",
       "[54412 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>임신 성공 확률</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>0.073774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>0.183785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>0.219433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>0.283400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>0.254783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54407</th>\n",
       "      <td>TEST_54407</td>\n",
       "      <td>0.287154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54408</th>\n",
       "      <td>TEST_54408</td>\n",
       "      <td>0.014109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54409</th>\n",
       "      <td>TEST_54409</td>\n",
       "      <td>0.293662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54410</th>\n",
       "      <td>TEST_54410</td>\n",
       "      <td>0.270870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54411</th>\n",
       "      <td>TEST_54411</td>\n",
       "      <td>0.160930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54412 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T11:07:03.096590Z",
     "start_time": "2025-04-05T11:07:03.049586Z"
    }
   },
   "cell_type": "code",
   "source": "submission.to_csv(f'./Submission/TabR_{seed}.csv', index=False)",
   "id": "9ff3a0f8308818f3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:32:16.993905Z",
     "start_time": "2025-04-04T08:32:16.978904Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5a8014e0753892d0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
